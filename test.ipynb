{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "600e1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal, NamedTuple\n",
    "\n",
    "from TabM import Model, make_parameter_groups\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import time\n",
    "import cpuinfo\n",
    "import torch\n",
    "import psutil\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import platform\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score, accuracy_score, roc_auc_score, precision_recall_curve, auc, f1_score, recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "79bad24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / (1024 ** 2)\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "829db29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    start_time = time.time()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch).cpu().numpy()\n",
    "            preds = (outputs >= 0.5).astype(int)\n",
    "            all_predictions.extend(preds if preds.ndim == 1 else preds.tolist())\n",
    "            all_labels.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    M = \"OK-\"\n",
    "    if len(set(all_predictions)) == 1:\n",
    "        M = \"ER-\"\n",
    "        \n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "    aupr = average_precision_score(all_labels, all_predictions)\n",
    "    Far = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions, digits=5))\n",
    "    errors = [(i, p, l) for i, (p, l) in enumerate(zip(all_predictions, all_labels)) if p != l]\n",
    "    print(f\"Total Errors: {len(errors)}\")\n",
    "    for i, pred, label in errors[:5]:\n",
    "        print(f\"Index: {i}, Predicted: {pred}, Actual: {label}\")\n",
    "    memory_usage = get_memory_usage()\n",
    "    return f\"{M} Accuracy: {accuracy:.5f}, Precision: {precision:.5f}, Recall: {recall:.5f}, F1: {f1:.5f}, ROC AUC: {roc_auc:.5f}, AUPR (PR-AUC): {aupr:.5f}, Sensitivity: {sensitivity:.5f}, Specificity: {specificity:.5f}, Far: {Far}, False Positive Rate (FPR): {false_positive_rate:.5f}, False Negative Rate (FNR): {false_negative_rate:.5f}, Runtime: {elapsed_time:.3f} sec , Memory Usage: {memory_usage:.2f} MB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9629d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, epochs, train_loader, val_loader, test_loader):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(X_train_batch)\n",
    "            loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss_batch = 0\n",
    "                    for X_val_batch, y_val_batch in val_loader:\n",
    "                        outputs_val = model(X_val_batch)\n",
    "                        loss_val = criterion(outputs_val, y_val_batch.float())\n",
    "                        val_loss_batch += loss_val.item()\n",
    "                    train_loss_batch = 0\n",
    "                    for X_train_batch, y_train_batch in train_loader:\n",
    "                        outputs_train = model(X_train_batch)\n",
    "                        loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "                        train_loss_batch += loss_train.item()\n",
    "                        \n",
    "                    val_loss_avg = val_loss_batch / len(val_loader)\n",
    "                    train_loss_avg = train_loss_batch / len(train_loader)\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lrnum = param_group['lr']\n",
    "                train_losses.append(train_loss_avg)\n",
    "                val_losses.append(val_loss_avg)\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss_train.item():.4f}, Val Loss: {val_loss_avg:.4f}, LR: {lrnum:.10f}')\n",
    "                model.train()\n",
    "        \n",
    "        if test_loader and epoch % 10 == 0:\n",
    "            RES = test(model, test_loader)\n",
    "            print(f\"Epoch {epoch+1}: {RES}\")\n",
    "\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "afd39380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', warmup_epochs=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            if self.verbose:\n",
    "                print(f\"Warmup epoch [{epoch+1}/{self.warmup_epochs}]. Skipping EarlyStopping check.\")\n",
    "            return\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, epochs, train_loader, val_loader, device, early_stopping):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(X_train_batch)\n",
    "            loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            running_train_loss += loss_train.item()\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                outputs_val = model(X_val_batch)\n",
    "                loss_val = criterion(outputs_val, y_val_batch.float())\n",
    "                running_val_loss += loss_val.item()\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] | Train Loss: {epoch_train_loss:.4f} | Val Loss: {epoch_val_loss:.4f}')\n",
    "        early_stopping(epoch_val_loss, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Loading best model from '{early_stopping.path}' with validation loss: {early_stopping.val_loss_min:.4f}\")\n",
    "    model.load_state_dict(torch.load(early_stopping.path, weights_only=True))\n",
    "\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('loss_per_epoch.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b1df07b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== D: cpu ===========\n",
      "\n",
      " Label\n",
      "1    5675\n",
      "0    4325\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def CONVERT(df):\n",
    "    X = df.drop(' Label', axis=1)\n",
    "    y = df[' Label']\n",
    "    X.columns = X.columns.str.strip()\n",
    "    important_features = ['Bwd Packet Length Std', 'Average Packet Size', 'Flow Duration', 'Flow IAT Std']\n",
    "    important_df = X[important_features] * 2.0\n",
    "    remaining_df = X.drop(columns=important_features)\n",
    "    X = pd.concat([remaining_df, important_df], axis=1)\n",
    "    return X, y\n",
    "\n",
    "train_loader, val_loader, test_loader = None, None, None\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'=========== D: {device} ===========\\n')\n",
    "current_dir = \"Data/\"\n",
    "df = pd.read_csv(os.path.join(current_dir, 'DDos.csv'))\n",
    "encoder = LabelEncoder()\n",
    "df[' Label'] = encoder.fit_transform(df[' Label'])\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna()\n",
    "df = df.sample(n=10000, random_state=28, replace=False)\n",
    "X, y = CONVERT(df)\n",
    "print(y.value_counts())\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "b101b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "47ceddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "    def __init__(self, tabm):\n",
    "        super(MODEL, self).__init__()\n",
    "        self.tabm = tabm\n",
    "        self.C1 = nn.Conv1d(10, 16, 4)\n",
    "        self.C2 = nn.Conv1d(16, 16, 4)\n",
    "        self.C3 = nn.Conv1d(16, 16, 4)\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.F1 = nn.Linear(16, 32)\n",
    "        self.F2 = nn.Linear(32, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.attn_weights = nn.Parameter(torch.randn(78))\n",
    "\n",
    "    def forward(self, x=None, x_cat=None):\n",
    "        t = self.tabm(x, x_cat)\n",
    "        attention = torch.matmul(x, self.attn_weights)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(1)\n",
    "        y = (x * attention).unsqueeze(1)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        x = torch.cat((x, y, t), dim=1)\n",
    "        x = self.tanh(self.C1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tanh(self.C2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tanh(self.C3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x).squeeze(2)\n",
    "        x = self.tanh(self.F1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.F2(x)).squeeze(1)\n",
    "        return x\n",
    "\n",
    "backbone_config = {\n",
    "    'type': 'MLP',\n",
    "    'n_blocks': 2,\n",
    "    'd_block': 32,\n",
    "    'dropout': 0.1,\n",
    "}\n",
    "tabm = Model(\n",
    "    n_num_features=78,\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=78,\n",
    "    backbone=backbone_config,\n",
    "    num_embeddings=None,\n",
    "    arch_type='tabm',\n",
    "    bins=None,\n",
    "    k=8\n",
    ")\n",
    "\n",
    "model = MODEL(tabm=tabm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "5a37b089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== TP: 29,407 ===========\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "SL = len(train_loader) * epochs\n",
    "model.to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=SL, eta_min=1e-5)\n",
    "early_stopper = EarlyStopping(patience=30, verbose=True, path='best_model.pt', warmup_epochs=100)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"=========== TP: {total_params:,} ===========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "ac324016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] | Train Loss: 0.4059 | Val Loss: 0.0602\n",
      "Warmup epoch [1/100]. Skipping EarlyStopping check.\n",
      "Epoch [2/200] | Train Loss: 0.0498 | Val Loss: 0.0322\n",
      "Warmup epoch [2/100]. Skipping EarlyStopping check.\n",
      "Epoch [3/200] | Train Loss: 0.0410 | Val Loss: 0.0188\n",
      "Warmup epoch [3/100]. Skipping EarlyStopping check.\n",
      "Epoch [4/200] | Train Loss: 0.0331 | Val Loss: 0.0197\n",
      "Warmup epoch [4/100]. Skipping EarlyStopping check.\n",
      "Epoch [5/200] | Train Loss: 0.0353 | Val Loss: 0.0160\n",
      "Warmup epoch [5/100]. Skipping EarlyStopping check.\n",
      "Epoch [6/200] | Train Loss: 0.0314 | Val Loss: 0.0330\n",
      "Warmup epoch [6/100]. Skipping EarlyStopping check.\n",
      "Epoch [7/200] | Train Loss: 0.0268 | Val Loss: 0.0132\n",
      "Warmup epoch [7/100]. Skipping EarlyStopping check.\n",
      "Epoch [8/200] | Train Loss: 0.0267 | Val Loss: 0.0143\n",
      "Warmup epoch [8/100]. Skipping EarlyStopping check.\n",
      "Epoch [9/200] | Train Loss: 0.0227 | Val Loss: 0.0110\n",
      "Warmup epoch [9/100]. Skipping EarlyStopping check.\n",
      "Epoch [10/200] | Train Loss: 0.0229 | Val Loss: 0.0098\n",
      "Warmup epoch [10/100]. Skipping EarlyStopping check.\n",
      "Epoch [11/200] | Train Loss: 0.0240 | Val Loss: 0.0116\n",
      "Warmup epoch [11/100]. Skipping EarlyStopping check.\n",
      "Epoch [12/200] | Train Loss: 0.0209 | Val Loss: 0.0088\n",
      "Warmup epoch [12/100]. Skipping EarlyStopping check.\n",
      "Epoch [13/200] | Train Loss: 0.0208 | Val Loss: 0.0077\n",
      "Warmup epoch [13/100]. Skipping EarlyStopping check.\n",
      "Epoch [14/200] | Train Loss: 0.0180 | Val Loss: 0.0080\n",
      "Warmup epoch [14/100]. Skipping EarlyStopping check.\n",
      "Epoch [15/200] | Train Loss: 0.0172 | Val Loss: 0.0087\n",
      "Warmup epoch [15/100]. Skipping EarlyStopping check.\n",
      "Epoch [16/200] | Train Loss: 0.0162 | Val Loss: 0.0060\n",
      "Warmup epoch [16/100]. Skipping EarlyStopping check.\n",
      "Epoch [17/200] | Train Loss: 0.0141 | Val Loss: 0.0057\n",
      "Warmup epoch [17/100]. Skipping EarlyStopping check.\n",
      "Epoch [18/200] | Train Loss: 0.0130 | Val Loss: 0.0074\n",
      "Warmup epoch [18/100]. Skipping EarlyStopping check.\n",
      "Epoch [19/200] | Train Loss: 0.0129 | Val Loss: 0.0058\n",
      "Warmup epoch [19/100]. Skipping EarlyStopping check.\n",
      "Epoch [20/200] | Train Loss: 0.0104 | Val Loss: 0.0080\n",
      "Warmup epoch [20/100]. Skipping EarlyStopping check.\n",
      "Epoch [21/200] | Train Loss: 0.0156 | Val Loss: 0.0059\n",
      "Warmup epoch [21/100]. Skipping EarlyStopping check.\n",
      "Epoch [22/200] | Train Loss: 0.0105 | Val Loss: 0.0060\n",
      "Warmup epoch [22/100]. Skipping EarlyStopping check.\n",
      "Epoch [23/200] | Train Loss: 0.0086 | Val Loss: 0.0045\n",
      "Warmup epoch [23/100]. Skipping EarlyStopping check.\n",
      "Epoch [24/200] | Train Loss: 0.0102 | Val Loss: 0.0039\n",
      "Warmup epoch [24/100]. Skipping EarlyStopping check.\n",
      "Epoch [25/200] | Train Loss: 0.0076 | Val Loss: 0.0049\n",
      "Warmup epoch [25/100]. Skipping EarlyStopping check.\n",
      "Epoch [26/200] | Train Loss: 0.0077 | Val Loss: 0.0041\n",
      "Warmup epoch [26/100]. Skipping EarlyStopping check.\n",
      "Epoch [27/200] | Train Loss: 0.0093 | Val Loss: 0.0071\n",
      "Warmup epoch [27/100]. Skipping EarlyStopping check.\n",
      "Epoch [28/200] | Train Loss: 0.0099 | Val Loss: 0.0131\n",
      "Warmup epoch [28/100]. Skipping EarlyStopping check.\n",
      "Epoch [29/200] | Train Loss: 0.0077 | Val Loss: 0.0057\n",
      "Warmup epoch [29/100]. Skipping EarlyStopping check.\n",
      "Epoch [30/200] | Train Loss: 0.0061 | Val Loss: 0.0044\n",
      "Warmup epoch [30/100]. Skipping EarlyStopping check.\n",
      "Epoch [31/200] | Train Loss: 0.0061 | Val Loss: 0.0047\n",
      "Warmup epoch [31/100]. Skipping EarlyStopping check.\n",
      "Epoch [32/200] | Train Loss: 0.0082 | Val Loss: 0.0021\n",
      "Warmup epoch [32/100]. Skipping EarlyStopping check.\n",
      "Epoch [33/200] | Train Loss: 0.0077 | Val Loss: 0.0021\n",
      "Warmup epoch [33/100]. Skipping EarlyStopping check.\n",
      "Epoch [34/200] | Train Loss: 0.0043 | Val Loss: 0.0025\n",
      "Warmup epoch [34/100]. Skipping EarlyStopping check.\n",
      "Epoch [35/200] | Train Loss: 0.0082 | Val Loss: 0.0004\n",
      "Warmup epoch [35/100]. Skipping EarlyStopping check.\n",
      "Epoch [36/200] | Train Loss: 0.0104 | Val Loss: 0.0013\n",
      "Warmup epoch [36/100]. Skipping EarlyStopping check.\n",
      "Epoch [37/200] | Train Loss: 0.0055 | Val Loss: 0.0007\n",
      "Warmup epoch [37/100]. Skipping EarlyStopping check.\n",
      "Epoch [38/200] | Train Loss: 0.0042 | Val Loss: 0.0008\n",
      "Warmup epoch [38/100]. Skipping EarlyStopping check.\n",
      "Epoch [39/200] | Train Loss: 0.0058 | Val Loss: 0.0032\n",
      "Warmup epoch [39/100]. Skipping EarlyStopping check.\n",
      "Epoch [40/200] | Train Loss: 0.0050 | Val Loss: 0.0008\n",
      "Warmup epoch [40/100]. Skipping EarlyStopping check.\n",
      "Epoch [41/200] | Train Loss: 0.0058 | Val Loss: 0.0189\n",
      "Warmup epoch [41/100]. Skipping EarlyStopping check.\n",
      "Epoch [42/200] | Train Loss: 0.0097 | Val Loss: 0.0014\n",
      "Warmup epoch [42/100]. Skipping EarlyStopping check.\n",
      "Epoch [43/200] | Train Loss: 0.0044 | Val Loss: 0.0075\n",
      "Warmup epoch [43/100]. Skipping EarlyStopping check.\n",
      "Epoch [44/200] | Train Loss: 0.0023 | Val Loss: 0.0062\n",
      "Warmup epoch [44/100]. Skipping EarlyStopping check.\n",
      "Epoch [45/200] | Train Loss: 0.0044 | Val Loss: 0.0018\n",
      "Warmup epoch [45/100]. Skipping EarlyStopping check.\n",
      "Epoch [46/200] | Train Loss: 0.0049 | Val Loss: 0.0044\n",
      "Warmup epoch [46/100]. Skipping EarlyStopping check.\n",
      "Epoch [47/200] | Train Loss: 0.0029 | Val Loss: 0.0057\n",
      "Warmup epoch [47/100]. Skipping EarlyStopping check.\n",
      "Epoch [48/200] | Train Loss: 0.0025 | Val Loss: 0.0023\n",
      "Warmup epoch [48/100]. Skipping EarlyStopping check.\n",
      "Epoch [49/200] | Train Loss: 0.0028 | Val Loss: 0.0045\n",
      "Warmup epoch [49/100]. Skipping EarlyStopping check.\n",
      "Epoch [50/200] | Train Loss: 0.0042 | Val Loss: 0.0012\n",
      "Warmup epoch [50/100]. Skipping EarlyStopping check.\n",
      "Epoch [51/200] | Train Loss: 0.0020 | Val Loss: 0.0061\n",
      "Warmup epoch [51/100]. Skipping EarlyStopping check.\n",
      "Epoch [52/200] | Train Loss: 0.0046 | Val Loss: 0.0006\n",
      "Warmup epoch [52/100]. Skipping EarlyStopping check.\n",
      "Epoch [53/200] | Train Loss: 0.0044 | Val Loss: 0.0004\n",
      "Warmup epoch [53/100]. Skipping EarlyStopping check.\n",
      "Epoch [54/200] | Train Loss: 0.0066 | Val Loss: 0.0007\n",
      "Warmup epoch [54/100]. Skipping EarlyStopping check.\n",
      "Epoch [55/200] | Train Loss: 0.0028 | Val Loss: 0.0007\n",
      "Warmup epoch [55/100]. Skipping EarlyStopping check.\n",
      "Epoch [56/200] | Train Loss: 0.0034 | Val Loss: 0.0002\n",
      "Warmup epoch [56/100]. Skipping EarlyStopping check.\n",
      "Epoch [57/200] | Train Loss: 0.0030 | Val Loss: 0.0007\n",
      "Warmup epoch [57/100]. Skipping EarlyStopping check.\n",
      "Epoch [58/200] | Train Loss: 0.0013 | Val Loss: 0.0003\n",
      "Warmup epoch [58/100]. Skipping EarlyStopping check.\n",
      "Epoch [59/200] | Train Loss: 0.0019 | Val Loss: 0.0013\n",
      "Warmup epoch [59/100]. Skipping EarlyStopping check.\n",
      "Epoch [60/200] | Train Loss: 0.0035 | Val Loss: 0.0001\n",
      "Warmup epoch [60/100]. Skipping EarlyStopping check.\n",
      "Epoch [61/200] | Train Loss: 0.0022 | Val Loss: 0.0002\n",
      "Warmup epoch [61/100]. Skipping EarlyStopping check.\n",
      "Epoch [62/200] | Train Loss: 0.0030 | Val Loss: 0.0006\n",
      "Warmup epoch [62/100]. Skipping EarlyStopping check.\n",
      "Epoch [63/200] | Train Loss: 0.0021 | Val Loss: 0.0001\n",
      "Warmup epoch [63/100]. Skipping EarlyStopping check.\n",
      "Epoch [64/200] | Train Loss: 0.0016 | Val Loss: 0.0004\n",
      "Warmup epoch [64/100]. Skipping EarlyStopping check.\n",
      "Epoch [65/200] | Train Loss: 0.0025 | Val Loss: 0.0011\n",
      "Warmup epoch [65/100]. Skipping EarlyStopping check.\n",
      "Epoch [66/200] | Train Loss: 0.0025 | Val Loss: 0.0001\n",
      "Warmup epoch [66/100]. Skipping EarlyStopping check.\n",
      "Epoch [67/200] | Train Loss: 0.0020 | Val Loss: 0.0001\n",
      "Warmup epoch [67/100]. Skipping EarlyStopping check.\n",
      "Epoch [68/200] | Train Loss: 0.0012 | Val Loss: 0.0038\n",
      "Warmup epoch [68/100]. Skipping EarlyStopping check.\n",
      "Epoch [69/200] | Train Loss: 0.0042 | Val Loss: 0.0001\n",
      "Warmup epoch [69/100]. Skipping EarlyStopping check.\n",
      "Epoch [70/200] | Train Loss: 0.0015 | Val Loss: 0.0001\n",
      "Warmup epoch [70/100]. Skipping EarlyStopping check.\n",
      "Epoch [71/200] | Train Loss: 0.0012 | Val Loss: 0.0002\n",
      "Warmup epoch [71/100]. Skipping EarlyStopping check.\n",
      "Epoch [72/200] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [72/100]. Skipping EarlyStopping check.\n",
      "Epoch [73/200] | Train Loss: 0.0005 | Val Loss: 0.0001\n",
      "Warmup epoch [73/100]. Skipping EarlyStopping check.\n",
      "Epoch [74/200] | Train Loss: 0.0008 | Val Loss: 0.0000\n",
      "Warmup epoch [74/100]. Skipping EarlyStopping check.\n",
      "Epoch [75/200] | Train Loss: 0.0038 | Val Loss: 0.0001\n",
      "Warmup epoch [75/100]. Skipping EarlyStopping check.\n",
      "Epoch [76/200] | Train Loss: 0.0009 | Val Loss: 0.0046\n",
      "Warmup epoch [76/100]. Skipping EarlyStopping check.\n",
      "Epoch [77/200] | Train Loss: 0.0037 | Val Loss: 0.0045\n",
      "Warmup epoch [77/100]. Skipping EarlyStopping check.\n",
      "Epoch [78/200] | Train Loss: 0.0014 | Val Loss: 0.0002\n",
      "Warmup epoch [78/100]. Skipping EarlyStopping check.\n",
      "Epoch [79/200] | Train Loss: 0.0003 | Val Loss: 0.0001\n",
      "Warmup epoch [79/100]. Skipping EarlyStopping check.\n",
      "Epoch [80/200] | Train Loss: 0.0014 | Val Loss: 0.0001\n",
      "Warmup epoch [80/100]. Skipping EarlyStopping check.\n",
      "Epoch [81/200] | Train Loss: 0.0011 | Val Loss: 0.0001\n",
      "Warmup epoch [81/100]. Skipping EarlyStopping check.\n",
      "Epoch [82/200] | Train Loss: 0.0029 | Val Loss: 0.0008\n",
      "Warmup epoch [82/100]. Skipping EarlyStopping check.\n",
      "Epoch [83/200] | Train Loss: 0.0020 | Val Loss: 0.0008\n",
      "Warmup epoch [83/100]. Skipping EarlyStopping check.\n",
      "Epoch [84/200] | Train Loss: 0.0018 | Val Loss: 0.0004\n",
      "Warmup epoch [84/100]. Skipping EarlyStopping check.\n",
      "Epoch [85/200] | Train Loss: 0.0009 | Val Loss: 0.0033\n",
      "Warmup epoch [85/100]. Skipping EarlyStopping check.\n",
      "Epoch [86/200] | Train Loss: 0.0001 | Val Loss: 0.0029\n",
      "Warmup epoch [86/100]. Skipping EarlyStopping check.\n",
      "Epoch [87/200] | Train Loss: 0.0001 | Val Loss: 0.0033\n",
      "Warmup epoch [87/100]. Skipping EarlyStopping check.\n",
      "Epoch [88/200] | Train Loss: 0.0018 | Val Loss: 0.0040\n",
      "Warmup epoch [88/100]. Skipping EarlyStopping check.\n",
      "Epoch [89/200] | Train Loss: 0.0021 | Val Loss: 0.0009\n",
      "Warmup epoch [89/100]. Skipping EarlyStopping check.\n",
      "Epoch [90/200] | Train Loss: 0.0017 | Val Loss: 0.0017\n",
      "Warmup epoch [90/100]. Skipping EarlyStopping check.\n",
      "Epoch [91/200] | Train Loss: 0.0003 | Val Loss: 0.0018\n",
      "Warmup epoch [91/100]. Skipping EarlyStopping check.\n",
      "Epoch [92/200] | Train Loss: 0.0002 | Val Loss: 0.0014\n",
      "Warmup epoch [92/100]. Skipping EarlyStopping check.\n",
      "Epoch [93/200] | Train Loss: 0.0001 | Val Loss: 0.0013\n",
      "Warmup epoch [93/100]. Skipping EarlyStopping check.\n",
      "Epoch [94/200] | Train Loss: 0.0007 | Val Loss: 0.0011\n",
      "Warmup epoch [94/100]. Skipping EarlyStopping check.\n",
      "Epoch [95/200] | Train Loss: 0.0016 | Val Loss: 0.0001\n",
      "Warmup epoch [95/100]. Skipping EarlyStopping check.\n",
      "Epoch [96/200] | Train Loss: 0.0003 | Val Loss: 0.0003\n",
      "Warmup epoch [96/100]. Skipping EarlyStopping check.\n",
      "Epoch [97/200] | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "Warmup epoch [97/100]. Skipping EarlyStopping check.\n",
      "Epoch [98/200] | Train Loss: 0.0010 | Val Loss: 0.0059\n",
      "Warmup epoch [98/100]. Skipping EarlyStopping check.\n",
      "Epoch [99/200] | Train Loss: 0.0023 | Val Loss: 0.0035\n",
      "Warmup epoch [99/100]. Skipping EarlyStopping check.\n",
      "Epoch [100/200] | Train Loss: 0.0001 | Val Loss: 0.0022\n",
      "Warmup epoch [100/100]. Skipping EarlyStopping check.\n",
      "Epoch [101/200] | Train Loss: 0.0002 | Val Loss: 0.0017\n",
      "Validation loss decreased (inf --> 0.001703).  Saving model ...\n",
      "Epoch [102/200] | Train Loss: 0.0002 | Val Loss: 0.0019\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [103/200] | Train Loss: 0.0005 | Val Loss: 0.0026\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [104/200] | Train Loss: 0.0031 | Val Loss: 0.0032\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [105/200] | Train Loss: 0.0017 | Val Loss: 0.0009\n",
      "Validation loss decreased (0.001703 --> 0.000910).  Saving model ...\n",
      "Epoch [106/200] | Train Loss: 0.0014 | Val Loss: 0.0019\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [107/200] | Train Loss: 0.0002 | Val Loss: 0.0010\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [108/200] | Train Loss: 0.0001 | Val Loss: 0.0014\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [109/200] | Train Loss: 0.0002 | Val Loss: 0.0011\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [110/200] | Train Loss: 0.0001 | Val Loss: 0.0011\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [111/200] | Train Loss: 0.0001 | Val Loss: 0.0011\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [112/200] | Train Loss: 0.0000 | Val Loss: 0.0012\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [113/200] | Train Loss: 0.0001 | Val Loss: 0.0012\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [114/200] | Train Loss: 0.0001 | Val Loss: 0.0011\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [115/200] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000910 --> 0.000012).  Saving model ...\n",
      "Epoch [116/200] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000012 --> 0.000009).  Saving model ...\n",
      "Epoch [117/200] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [118/200] | Train Loss: 0.0015 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [119/200] | Train Loss: 0.0015 | Val Loss: 0.0010\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [120/200] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [121/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [122/200] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [123/200] | Train Loss: 0.0022 | Val Loss: 0.0003\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [124/200] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [125/200] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [126/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [127/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [128/200] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [129/200] | Train Loss: 0.0007 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch [130/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch [131/200] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch [132/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch [133/200] | Train Loss: 0.0012 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch [134/200] | Train Loss: 0.0005 | Val Loss: 0.0003\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch [135/200] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch [136/200] | Train Loss: 0.0002 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch [137/200] | Train Loss: 0.0000 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch [138/200] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch [139/200] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch [140/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch [141/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch [142/200] | Train Loss: 0.0001 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch [143/200] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch [144/200] | Train Loss: 0.0003 | Val Loss: 0.0002\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch [145/200] | Train Loss: 0.0002 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch [146/200] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping triggered\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.0000\n",
      "Confusion Matrix:\n",
      "[[631   0]\n",
      " [  0 869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000       631\n",
      "           1    1.00000   1.00000   1.00000       869\n",
      "\n",
      "    accuracy                        1.00000      1500\n",
      "   macro avg    1.00000   1.00000   1.00000      1500\n",
      "weighted avg    1.00000   1.00000   1.00000      1500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00000, Precision: 1.00000, Recall: 1.00000, F1: 1.00000, ROC AUC: 1.00000, AUPR (PR-AUC): 1.00000, Sensitivity: 1.00000, Specificity: 1.00000, Far: 0.0, False Positive Rate (FPR): 0.00000, False Negative Rate (FNR): 0.00000, Runtime: 0.036 sec , Memory Usage: 513.13 MB\n"
     ]
    }
   ],
   "source": [
    "best_model = train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    epochs=epochs,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=device,\n",
    "    early_stopping=early_stopper\n",
    ")\n",
    "RES = test(best_model, test_loader)\n",
    "print(RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a3648a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== SEED: 28 , FOLD: 1/4, D: cpu ===========\n",
      " Label\n",
      "1    5675\n",
      "0    4325\n",
      "Name: count, dtype: int64\n",
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/150] | Train Loss: 0.4152 | Val Loss: 0.0460\n",
      "Warmup epoch [1/100]. Skipping EarlyStopping check.\n",
      "Epoch [2/150] | Train Loss: 0.0500 | Val Loss: 0.0369\n",
      "Warmup epoch [2/100]. Skipping EarlyStopping check.\n",
      "Epoch [3/150] | Train Loss: 0.0425 | Val Loss: 0.0260\n",
      "Warmup epoch [3/100]. Skipping EarlyStopping check.\n",
      "Epoch [4/150] | Train Loss: 0.0332 | Val Loss: 0.0240\n",
      "Warmup epoch [4/100]. Skipping EarlyStopping check.\n",
      "Epoch [5/150] | Train Loss: 0.0288 | Val Loss: 0.0172\n",
      "Warmup epoch [5/100]. Skipping EarlyStopping check.\n",
      "Epoch [6/150] | Train Loss: 0.0259 | Val Loss: 0.0121\n",
      "Warmup epoch [6/100]. Skipping EarlyStopping check.\n",
      "Epoch [7/150] | Train Loss: 0.0197 | Val Loss: 0.0140\n",
      "Warmup epoch [7/100]. Skipping EarlyStopping check.\n",
      "Epoch [8/150] | Train Loss: 0.0198 | Val Loss: 0.0119\n",
      "Warmup epoch [8/100]. Skipping EarlyStopping check.\n",
      "Epoch [9/150] | Train Loss: 0.0153 | Val Loss: 0.0067\n",
      "Warmup epoch [9/100]. Skipping EarlyStopping check.\n",
      "Epoch [10/150] | Train Loss: 0.0137 | Val Loss: 0.0231\n",
      "Warmup epoch [10/100]. Skipping EarlyStopping check.\n",
      "Epoch [11/150] | Train Loss: 0.0133 | Val Loss: 0.0083\n",
      "Warmup epoch [11/100]. Skipping EarlyStopping check.\n",
      "Epoch [12/150] | Train Loss: 0.0135 | Val Loss: 0.0195\n",
      "Warmup epoch [12/100]. Skipping EarlyStopping check.\n",
      "Epoch [13/150] | Train Loss: 0.0085 | Val Loss: 0.0069\n",
      "Warmup epoch [13/100]. Skipping EarlyStopping check.\n",
      "Epoch [14/150] | Train Loss: 0.0082 | Val Loss: 0.0111\n",
      "Warmup epoch [14/100]. Skipping EarlyStopping check.\n",
      "Epoch [15/150] | Train Loss: 0.0072 | Val Loss: 0.0069\n",
      "Warmup epoch [15/100]. Skipping EarlyStopping check.\n",
      "Epoch [16/150] | Train Loss: 0.0096 | Val Loss: 0.0103\n",
      "Warmup epoch [16/100]. Skipping EarlyStopping check.\n",
      "Epoch [17/150] | Train Loss: 0.0094 | Val Loss: 0.0109\n",
      "Warmup epoch [17/100]. Skipping EarlyStopping check.\n",
      "Epoch [18/150] | Train Loss: 0.0066 | Val Loss: 0.0062\n",
      "Warmup epoch [18/100]. Skipping EarlyStopping check.\n",
      "Epoch [19/150] | Train Loss: 0.0078 | Val Loss: 0.0061\n",
      "Warmup epoch [19/100]. Skipping EarlyStopping check.\n",
      "Epoch [20/150] | Train Loss: 0.0072 | Val Loss: 0.0072\n",
      "Warmup epoch [20/100]. Skipping EarlyStopping check.\n",
      "Epoch [21/150] | Train Loss: 0.0068 | Val Loss: 0.0064\n",
      "Warmup epoch [21/100]. Skipping EarlyStopping check.\n",
      "Epoch [22/150] | Train Loss: 0.0075 | Val Loss: 0.0066\n",
      "Warmup epoch [22/100]. Skipping EarlyStopping check.\n",
      "Epoch [23/150] | Train Loss: 0.0057 | Val Loss: 0.0060\n",
      "Warmup epoch [23/100]. Skipping EarlyStopping check.\n",
      "Epoch [24/150] | Train Loss: 0.0080 | Val Loss: 0.0087\n",
      "Warmup epoch [24/100]. Skipping EarlyStopping check.\n",
      "Epoch [25/150] | Train Loss: 0.0056 | Val Loss: 0.0096\n",
      "Warmup epoch [25/100]. Skipping EarlyStopping check.\n",
      "Epoch [26/150] | Train Loss: 0.0055 | Val Loss: 0.0076\n",
      "Warmup epoch [26/100]. Skipping EarlyStopping check.\n",
      "Epoch [27/150] | Train Loss: 0.0061 | Val Loss: 0.0070\n",
      "Warmup epoch [27/100]. Skipping EarlyStopping check.\n",
      "Epoch [28/150] | Train Loss: 0.0053 | Val Loss: 0.0147\n",
      "Warmup epoch [28/100]. Skipping EarlyStopping check.\n",
      "Epoch [29/150] | Train Loss: 0.0055 | Val Loss: 0.0074\n",
      "Warmup epoch [29/100]. Skipping EarlyStopping check.\n",
      "Epoch [30/150] | Train Loss: 0.0056 | Val Loss: 0.0081\n",
      "Warmup epoch [30/100]. Skipping EarlyStopping check.\n",
      "Epoch [31/150] | Train Loss: 0.0065 | Val Loss: 0.0133\n",
      "Warmup epoch [31/100]. Skipping EarlyStopping check.\n",
      "Epoch [32/150] | Train Loss: 0.0050 | Val Loss: 0.0101\n",
      "Warmup epoch [32/100]. Skipping EarlyStopping check.\n",
      "Epoch [33/150] | Train Loss: 0.0041 | Val Loss: 0.0096\n",
      "Warmup epoch [33/100]. Skipping EarlyStopping check.\n",
      "Epoch [34/150] | Train Loss: 0.0031 | Val Loss: 0.0061\n",
      "Warmup epoch [34/100]. Skipping EarlyStopping check.\n",
      "Epoch [35/150] | Train Loss: 0.0041 | Val Loss: 0.0070\n",
      "Warmup epoch [35/100]. Skipping EarlyStopping check.\n",
      "Epoch [36/150] | Train Loss: 0.0033 | Val Loss: 0.0068\n",
      "Warmup epoch [36/100]. Skipping EarlyStopping check.\n",
      "Epoch [37/150] | Train Loss: 0.0031 | Val Loss: 0.0109\n",
      "Warmup epoch [37/100]. Skipping EarlyStopping check.\n",
      "Epoch [38/150] | Train Loss: 0.0030 | Val Loss: 0.0062\n",
      "Warmup epoch [38/100]. Skipping EarlyStopping check.\n",
      "Epoch [39/150] | Train Loss: 0.0025 | Val Loss: 0.0106\n",
      "Warmup epoch [39/100]. Skipping EarlyStopping check.\n",
      "Epoch [40/150] | Train Loss: 0.0060 | Val Loss: 0.0062\n",
      "Warmup epoch [40/100]. Skipping EarlyStopping check.\n",
      "Epoch [41/150] | Train Loss: 0.0037 | Val Loss: 0.0069\n",
      "Warmup epoch [41/100]. Skipping EarlyStopping check.\n",
      "Epoch [42/150] | Train Loss: 0.0028 | Val Loss: 0.0096\n",
      "Warmup epoch [42/100]. Skipping EarlyStopping check.\n",
      "Epoch [43/150] | Train Loss: 0.0033 | Val Loss: 0.0080\n",
      "Warmup epoch [43/100]. Skipping EarlyStopping check.\n",
      "Epoch [44/150] | Train Loss: 0.0025 | Val Loss: 0.0060\n",
      "Warmup epoch [44/100]. Skipping EarlyStopping check.\n",
      "Epoch [45/150] | Train Loss: 0.0025 | Val Loss: 0.0066\n",
      "Warmup epoch [45/100]. Skipping EarlyStopping check.\n",
      "Epoch [46/150] | Train Loss: 0.0026 | Val Loss: 0.0062\n",
      "Warmup epoch [46/100]. Skipping EarlyStopping check.\n",
      "Epoch [47/150] | Train Loss: 0.0021 | Val Loss: 0.0063\n",
      "Warmup epoch [47/100]. Skipping EarlyStopping check.\n",
      "Epoch [48/150] | Train Loss: 0.0029 | Val Loss: 0.0061\n",
      "Warmup epoch [48/100]. Skipping EarlyStopping check.\n",
      "Epoch [49/150] | Train Loss: 0.0037 | Val Loss: 0.0101\n",
      "Warmup epoch [49/100]. Skipping EarlyStopping check.\n",
      "Epoch [50/150] | Train Loss: 0.0039 | Val Loss: 0.0066\n",
      "Warmup epoch [50/100]. Skipping EarlyStopping check.\n",
      "Epoch [51/150] | Train Loss: 0.0026 | Val Loss: 0.0102\n",
      "Warmup epoch [51/100]. Skipping EarlyStopping check.\n",
      "Epoch [52/150] | Train Loss: 0.0022 | Val Loss: 0.0087\n",
      "Warmup epoch [52/100]. Skipping EarlyStopping check.\n",
      "Epoch [53/150] | Train Loss: 0.0025 | Val Loss: 0.0067\n",
      "Warmup epoch [53/100]. Skipping EarlyStopping check.\n",
      "Epoch [54/150] | Train Loss: 0.0019 | Val Loss: 0.0083\n",
      "Warmup epoch [54/100]. Skipping EarlyStopping check.\n",
      "Epoch [55/150] | Train Loss: 0.0021 | Val Loss: 0.0064\n",
      "Warmup epoch [55/100]. Skipping EarlyStopping check.\n",
      "Epoch [56/150] | Train Loss: 0.0015 | Val Loss: 0.0074\n",
      "Warmup epoch [56/100]. Skipping EarlyStopping check.\n",
      "Epoch [57/150] | Train Loss: 0.0020 | Val Loss: 0.0063\n",
      "Warmup epoch [57/100]. Skipping EarlyStopping check.\n",
      "Epoch [58/150] | Train Loss: 0.0016 | Val Loss: 0.0062\n",
      "Warmup epoch [58/100]. Skipping EarlyStopping check.\n",
      "Epoch [59/150] | Train Loss: 0.0019 | Val Loss: 0.0077\n",
      "Warmup epoch [59/100]. Skipping EarlyStopping check.\n",
      "Epoch [60/150] | Train Loss: 0.0024 | Val Loss: 0.0061\n",
      "Warmup epoch [60/100]. Skipping EarlyStopping check.\n",
      "Epoch [61/150] | Train Loss: 0.0019 | Val Loss: 0.0062\n",
      "Warmup epoch [61/100]. Skipping EarlyStopping check.\n",
      "Epoch [62/150] | Train Loss: 0.0019 | Val Loss: 0.0067\n",
      "Warmup epoch [62/100]. Skipping EarlyStopping check.\n",
      "Epoch [63/150] | Train Loss: 0.0016 | Val Loss: 0.0063\n",
      "Warmup epoch [63/100]. Skipping EarlyStopping check.\n",
      "Epoch [64/150] | Train Loss: 0.0017 | Val Loss: 0.0063\n",
      "Warmup epoch [64/100]. Skipping EarlyStopping check.\n",
      "Epoch [65/150] | Train Loss: 0.0045 | Val Loss: 0.0058\n",
      "Warmup epoch [65/100]. Skipping EarlyStopping check.\n",
      "Epoch [66/150] | Train Loss: 0.0020 | Val Loss: 0.0090\n",
      "Warmup epoch [66/100]. Skipping EarlyStopping check.\n",
      "Epoch [67/150] | Train Loss: 0.0017 | Val Loss: 0.0154\n",
      "Warmup epoch [67/100]. Skipping EarlyStopping check.\n",
      "Epoch [68/150] | Train Loss: 0.0026 | Val Loss: 0.0120\n",
      "Warmup epoch [68/100]. Skipping EarlyStopping check.\n",
      "Epoch [69/150] | Train Loss: 0.0011 | Val Loss: 0.0106\n",
      "Warmup epoch [69/100]. Skipping EarlyStopping check.\n",
      "Epoch [70/150] | Train Loss: 0.0018 | Val Loss: 0.0102\n",
      "Warmup epoch [70/100]. Skipping EarlyStopping check.\n",
      "Epoch [71/150] | Train Loss: 0.0011 | Val Loss: 0.0117\n",
      "Warmup epoch [71/100]. Skipping EarlyStopping check.\n",
      "Epoch [72/150] | Train Loss: 0.0006 | Val Loss: 0.0074\n",
      "Warmup epoch [72/100]. Skipping EarlyStopping check.\n",
      "Epoch [73/150] | Train Loss: 0.0007 | Val Loss: 0.0095\n",
      "Warmup epoch [73/100]. Skipping EarlyStopping check.\n",
      "Epoch [74/150] | Train Loss: 0.0005 | Val Loss: 0.0089\n",
      "Warmup epoch [74/100]. Skipping EarlyStopping check.\n",
      "Epoch [75/150] | Train Loss: 0.0008 | Val Loss: 0.0109\n",
      "Warmup epoch [75/100]. Skipping EarlyStopping check.\n",
      "Epoch [76/150] | Train Loss: 0.0004 | Val Loss: 0.0100\n",
      "Warmup epoch [76/100]. Skipping EarlyStopping check.\n",
      "Epoch [77/150] | Train Loss: 0.0008 | Val Loss: 0.0089\n",
      "Warmup epoch [77/100]. Skipping EarlyStopping check.\n",
      "Epoch [78/150] | Train Loss: 0.0002 | Val Loss: 0.0082\n",
      "Warmup epoch [78/100]. Skipping EarlyStopping check.\n",
      "Epoch [79/150] | Train Loss: 0.0001 | Val Loss: 0.0081\n",
      "Warmup epoch [79/100]. Skipping EarlyStopping check.\n",
      "Epoch [80/150] | Train Loss: 0.0004 | Val Loss: 0.0096\n",
      "Warmup epoch [80/100]. Skipping EarlyStopping check.\n",
      "Epoch [81/150] | Train Loss: 0.0007 | Val Loss: 0.0177\n",
      "Warmup epoch [81/100]. Skipping EarlyStopping check.\n",
      "Epoch [82/150] | Train Loss: 0.0017 | Val Loss: 0.0075\n",
      "Warmup epoch [82/100]. Skipping EarlyStopping check.\n",
      "Epoch [83/150] | Train Loss: 0.0015 | Val Loss: 0.0070\n",
      "Warmup epoch [83/100]. Skipping EarlyStopping check.\n",
      "Epoch [84/150] | Train Loss: 0.0006 | Val Loss: 0.0124\n",
      "Warmup epoch [84/100]. Skipping EarlyStopping check.\n",
      "Epoch [85/150] | Train Loss: 0.0004 | Val Loss: 0.0080\n",
      "Warmup epoch [85/100]. Skipping EarlyStopping check.\n",
      "Epoch [86/150] | Train Loss: 0.0005 | Val Loss: 0.0103\n",
      "Warmup epoch [86/100]. Skipping EarlyStopping check.\n",
      "Epoch [87/150] | Train Loss: 0.0003 | Val Loss: 0.0114\n",
      "Warmup epoch [87/100]. Skipping EarlyStopping check.\n",
      "Epoch [88/150] | Train Loss: 0.0004 | Val Loss: 0.0132\n",
      "Warmup epoch [88/100]. Skipping EarlyStopping check.\n",
      "Epoch [89/150] | Train Loss: 0.0001 | Val Loss: 0.0118\n",
      "Warmup epoch [89/100]. Skipping EarlyStopping check.\n",
      "Epoch [90/150] | Train Loss: 0.0003 | Val Loss: 0.0115\n",
      "Warmup epoch [90/100]. Skipping EarlyStopping check.\n",
      "Epoch [91/150] | Train Loss: 0.0001 | Val Loss: 0.0074\n",
      "Warmup epoch [91/100]. Skipping EarlyStopping check.\n",
      "Epoch [92/150] | Train Loss: 0.0008 | Val Loss: 0.0104\n",
      "Warmup epoch [92/100]. Skipping EarlyStopping check.\n",
      "Epoch [93/150] | Train Loss: 0.0001 | Val Loss: 0.0099\n",
      "Warmup epoch [93/100]. Skipping EarlyStopping check.\n",
      "Epoch [94/150] | Train Loss: 0.0001 | Val Loss: 0.0083\n",
      "Warmup epoch [94/100]. Skipping EarlyStopping check.\n",
      "Epoch [95/150] | Train Loss: 0.0000 | Val Loss: 0.0089\n",
      "Warmup epoch [95/100]. Skipping EarlyStopping check.\n",
      "Epoch [96/150] | Train Loss: 0.0000 | Val Loss: 0.0092\n",
      "Warmup epoch [96/100]. Skipping EarlyStopping check.\n",
      "Epoch [97/150] | Train Loss: 0.0003 | Val Loss: 0.0074\n",
      "Warmup epoch [97/100]. Skipping EarlyStopping check.\n",
      "Epoch [98/150] | Train Loss: 0.0001 | Val Loss: 0.0080\n",
      "Warmup epoch [98/100]. Skipping EarlyStopping check.\n",
      "Epoch [99/150] | Train Loss: 0.0004 | Val Loss: 0.0128\n",
      "Warmup epoch [99/100]. Skipping EarlyStopping check.\n",
      "Epoch [100/150] | Train Loss: 0.0000 | Val Loss: 0.0122\n",
      "Warmup epoch [100/100]. Skipping EarlyStopping check.\n",
      "Epoch [101/150] | Train Loss: 0.0001 | Val Loss: 0.0109\n",
      "Validation loss decreased (inf --> 0.010915).  Saving model ...\n",
      "Epoch [102/150] | Train Loss: 0.0000 | Val Loss: 0.0115\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [103/150] | Train Loss: 0.0000 | Val Loss: 0.0119\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [104/150] | Train Loss: 0.0001 | Val Loss: 0.0118\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [105/150] | Train Loss: 0.0001 | Val Loss: 0.0136\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [106/150] | Train Loss: 0.0000 | Val Loss: 0.0136\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [107/150] | Train Loss: 0.0000 | Val Loss: 0.0137\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [108/150] | Train Loss: 0.0000 | Val Loss: 0.0139\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [109/150] | Train Loss: 0.0000 | Val Loss: 0.0139\n",
      "EarlyStopping counter: 8 out of 15\n",
      "Epoch [110/150] | Train Loss: 0.0000 | Val Loss: 0.0139\n",
      "EarlyStopping counter: 9 out of 15\n",
      "Epoch [111/150] | Train Loss: 0.0000 | Val Loss: 0.0146\n",
      "EarlyStopping counter: 10 out of 15\n",
      "Epoch [112/150] | Train Loss: 0.0003 | Val Loss: 0.0079\n",
      "Validation loss decreased (0.010915 --> 0.007864).  Saving model ...\n",
      "Epoch [113/150] | Train Loss: 0.0007 | Val Loss: 0.0140\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [114/150] | Train Loss: 0.0000 | Val Loss: 0.0140\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [115/150] | Train Loss: 0.0000 | Val Loss: 0.0140\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [116/150] | Train Loss: 0.0004 | Val Loss: 0.0100\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [117/150] | Train Loss: 0.0000 | Val Loss: 0.0109\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [118/150] | Train Loss: 0.0000 | Val Loss: 0.0110\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [119/150] | Train Loss: 0.0000 | Val Loss: 0.0112\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [120/150] | Train Loss: 0.0005 | Val Loss: 0.0087\n",
      "EarlyStopping counter: 8 out of 15\n",
      "Epoch [121/150] | Train Loss: 0.0001 | Val Loss: 0.0091\n",
      "EarlyStopping counter: 9 out of 15\n",
      "Epoch [122/150] | Train Loss: 0.0000 | Val Loss: 0.0092\n",
      "EarlyStopping counter: 10 out of 15\n",
      "Epoch [123/150] | Train Loss: 0.0000 | Val Loss: 0.0093\n",
      "EarlyStopping counter: 11 out of 15\n",
      "Epoch [124/150] | Train Loss: 0.0000 | Val Loss: 0.0097\n",
      "EarlyStopping counter: 12 out of 15\n",
      "Epoch [125/150] | Train Loss: 0.0000 | Val Loss: 0.0096\n",
      "EarlyStopping counter: 13 out of 15\n",
      "Epoch [126/150] | Train Loss: 0.0000 | Val Loss: 0.0097\n",
      "EarlyStopping counter: 14 out of 15\n",
      "Epoch [127/150] | Train Loss: 0.0000 | Val Loss: 0.0097\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping triggered\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.0079\n",
      "Confusion Matrix:\n",
      "[[637   0]\n",
      " [  0 863]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000       637\n",
      "           1    1.00000   1.00000   1.00000       863\n",
      "\n",
      "    accuracy                        1.00000      1500\n",
      "   macro avg    1.00000   1.00000   1.00000      1500\n",
      "weighted avg    1.00000   1.00000   1.00000      1500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00000, Precision: 1.00000, Recall: 1.00000, F1: 1.00000, ROC AUC: 1.00000, AUPR (PR-AUC): 1.00000, Sensitivity: 1.00000, Specificity: 1.00000, Far: 0.0, False Positive Rate (FPR): 0.00000, False Negative Rate (FNR): 0.00000, Runtime: 0.039 sec , Memory Usage: 608.29 MB\n",
      "=========== SEED: 7 , FOLD: 2/4, D: cpu ===========\n",
      " Label\n",
      "1    5734\n",
      "0    4266\n",
      "Name: count, dtype: int64\n",
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/150] | Train Loss: 0.3937 | Val Loss: 0.0520\n",
      "Warmup epoch [1/100]. Skipping EarlyStopping check.\n",
      "Epoch [2/150] | Train Loss: 0.0547 | Val Loss: 0.0281\n",
      "Warmup epoch [2/100]. Skipping EarlyStopping check.\n",
      "Epoch [3/150] | Train Loss: 0.0455 | Val Loss: 0.0314\n",
      "Warmup epoch [3/100]. Skipping EarlyStopping check.\n",
      "Epoch [4/150] | Train Loss: 0.0397 | Val Loss: 0.0209\n",
      "Warmup epoch [4/100]. Skipping EarlyStopping check.\n",
      "Epoch [5/150] | Train Loss: 0.0310 | Val Loss: 0.0150\n",
      "Warmup epoch [5/100]. Skipping EarlyStopping check.\n",
      "Epoch [6/150] | Train Loss: 0.0292 | Val Loss: 0.0234\n",
      "Warmup epoch [6/100]. Skipping EarlyStopping check.\n",
      "Epoch [7/150] | Train Loss: 0.0242 | Val Loss: 0.0103\n",
      "Warmup epoch [7/100]. Skipping EarlyStopping check.\n",
      "Epoch [8/150] | Train Loss: 0.0259 | Val Loss: 0.0096\n",
      "Warmup epoch [8/100]. Skipping EarlyStopping check.\n",
      "Epoch [9/150] | Train Loss: 0.0199 | Val Loss: 0.0076\n",
      "Warmup epoch [9/100]. Skipping EarlyStopping check.\n",
      "Epoch [10/150] | Train Loss: 0.0172 | Val Loss: 0.0058\n",
      "Warmup epoch [10/100]. Skipping EarlyStopping check.\n",
      "Epoch [11/150] | Train Loss: 0.0140 | Val Loss: 0.0037\n",
      "Warmup epoch [11/100]. Skipping EarlyStopping check.\n",
      "Epoch [12/150] | Train Loss: 0.0143 | Val Loss: 0.0111\n",
      "Warmup epoch [12/100]. Skipping EarlyStopping check.\n",
      "Epoch [13/150] | Train Loss: 0.0136 | Val Loss: 0.0044\n",
      "Warmup epoch [13/100]. Skipping EarlyStopping check.\n",
      "Epoch [14/150] | Train Loss: 0.0104 | Val Loss: 0.0053\n",
      "Warmup epoch [14/100]. Skipping EarlyStopping check.\n",
      "Epoch [15/150] | Train Loss: 0.0092 | Val Loss: 0.0013\n",
      "Warmup epoch [15/100]. Skipping EarlyStopping check.\n",
      "Epoch [16/150] | Train Loss: 0.0112 | Val Loss: 0.0024\n",
      "Warmup epoch [16/100]. Skipping EarlyStopping check.\n",
      "Epoch [17/150] | Train Loss: 0.0088 | Val Loss: 0.0034\n",
      "Warmup epoch [17/100]. Skipping EarlyStopping check.\n",
      "Epoch [18/150] | Train Loss: 0.0102 | Val Loss: 0.0013\n",
      "Warmup epoch [18/100]. Skipping EarlyStopping check.\n",
      "Epoch [19/150] | Train Loss: 0.0082 | Val Loss: 0.0010\n",
      "Warmup epoch [19/100]. Skipping EarlyStopping check.\n",
      "Epoch [20/150] | Train Loss: 0.0048 | Val Loss: 0.0015\n",
      "Warmup epoch [20/100]. Skipping EarlyStopping check.\n",
      "Epoch [21/150] | Train Loss: 0.0062 | Val Loss: 0.0006\n",
      "Warmup epoch [21/100]. Skipping EarlyStopping check.\n",
      "Epoch [22/150] | Train Loss: 0.0050 | Val Loss: 0.0015\n",
      "Warmup epoch [22/100]. Skipping EarlyStopping check.\n",
      "Epoch [23/150] | Train Loss: 0.0049 | Val Loss: 0.0013\n",
      "Warmup epoch [23/100]. Skipping EarlyStopping check.\n",
      "Epoch [24/150] | Train Loss: 0.0063 | Val Loss: 0.0071\n",
      "Warmup epoch [24/100]. Skipping EarlyStopping check.\n",
      "Epoch [25/150] | Train Loss: 0.0092 | Val Loss: 0.0014\n",
      "Warmup epoch [25/100]. Skipping EarlyStopping check.\n",
      "Epoch [26/150] | Train Loss: 0.0049 | Val Loss: 0.0005\n",
      "Warmup epoch [26/100]. Skipping EarlyStopping check.\n",
      "Epoch [27/150] | Train Loss: 0.0030 | Val Loss: 0.0003\n",
      "Warmup epoch [27/100]. Skipping EarlyStopping check.\n",
      "Epoch [28/150] | Train Loss: 0.0038 | Val Loss: 0.0003\n",
      "Warmup epoch [28/100]. Skipping EarlyStopping check.\n",
      "Epoch [29/150] | Train Loss: 0.0048 | Val Loss: 0.0007\n",
      "Warmup epoch [29/100]. Skipping EarlyStopping check.\n",
      "Epoch [30/150] | Train Loss: 0.0025 | Val Loss: 0.0005\n",
      "Warmup epoch [30/100]. Skipping EarlyStopping check.\n",
      "Epoch [31/150] | Train Loss: 0.0038 | Val Loss: 0.0002\n",
      "Warmup epoch [31/100]. Skipping EarlyStopping check.\n",
      "Epoch [32/150] | Train Loss: 0.0019 | Val Loss: 0.0002\n",
      "Warmup epoch [32/100]. Skipping EarlyStopping check.\n",
      "Epoch [33/150] | Train Loss: 0.0022 | Val Loss: 0.0005\n",
      "Warmup epoch [33/100]. Skipping EarlyStopping check.\n",
      "Epoch [34/150] | Train Loss: 0.0022 | Val Loss: 0.0001\n",
      "Warmup epoch [34/100]. Skipping EarlyStopping check.\n",
      "Epoch [35/150] | Train Loss: 0.0024 | Val Loss: 0.0002\n",
      "Warmup epoch [35/100]. Skipping EarlyStopping check.\n",
      "Epoch [36/150] | Train Loss: 0.0023 | Val Loss: 0.0003\n",
      "Warmup epoch [36/100]. Skipping EarlyStopping check.\n",
      "Epoch [37/150] | Train Loss: 0.0038 | Val Loss: 0.0002\n",
      "Warmup epoch [37/100]. Skipping EarlyStopping check.\n",
      "Epoch [38/150] | Train Loss: 0.0039 | Val Loss: 0.0005\n",
      "Warmup epoch [38/100]. Skipping EarlyStopping check.\n",
      "Epoch [39/150] | Train Loss: 0.0014 | Val Loss: 0.0028\n",
      "Warmup epoch [39/100]. Skipping EarlyStopping check.\n",
      "Epoch [40/150] | Train Loss: 0.0056 | Val Loss: 0.0002\n",
      "Warmup epoch [40/100]. Skipping EarlyStopping check.\n",
      "Epoch [41/150] | Train Loss: 0.0031 | Val Loss: 0.0002\n",
      "Warmup epoch [41/100]. Skipping EarlyStopping check.\n",
      "Epoch [42/150] | Train Loss: 0.0011 | Val Loss: 0.0001\n",
      "Warmup epoch [42/100]. Skipping EarlyStopping check.\n",
      "Epoch [43/150] | Train Loss: 0.0019 | Val Loss: 0.0043\n",
      "Warmup epoch [43/100]. Skipping EarlyStopping check.\n",
      "Epoch [44/150] | Train Loss: 0.0017 | Val Loss: 0.0003\n",
      "Warmup epoch [44/100]. Skipping EarlyStopping check.\n",
      "Epoch [45/150] | Train Loss: 0.0020 | Val Loss: 0.0002\n",
      "Warmup epoch [45/100]. Skipping EarlyStopping check.\n",
      "Epoch [46/150] | Train Loss: 0.0020 | Val Loss: 0.0001\n",
      "Warmup epoch [46/100]. Skipping EarlyStopping check.\n",
      "Epoch [47/150] | Train Loss: 0.0009 | Val Loss: 0.0002\n",
      "Warmup epoch [47/100]. Skipping EarlyStopping check.\n",
      "Epoch [48/150] | Train Loss: 0.0047 | Val Loss: 0.0003\n",
      "Warmup epoch [48/100]. Skipping EarlyStopping check.\n",
      "Epoch [49/150] | Train Loss: 0.0010 | Val Loss: 0.0001\n",
      "Warmup epoch [49/100]. Skipping EarlyStopping check.\n",
      "Epoch [50/150] | Train Loss: 0.0018 | Val Loss: 0.0001\n",
      "Warmup epoch [50/100]. Skipping EarlyStopping check.\n",
      "Epoch [51/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [51/100]. Skipping EarlyStopping check.\n",
      "Epoch [52/150] | Train Loss: 0.0008 | Val Loss: 0.0024\n",
      "Warmup epoch [52/100]. Skipping EarlyStopping check.\n",
      "Epoch [53/150] | Train Loss: 0.0021 | Val Loss: 0.0001\n",
      "Warmup epoch [53/100]. Skipping EarlyStopping check.\n",
      "Epoch [54/150] | Train Loss: 0.0014 | Val Loss: 0.0001\n",
      "Warmup epoch [54/100]. Skipping EarlyStopping check.\n",
      "Epoch [55/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [55/100]. Skipping EarlyStopping check.\n",
      "Epoch [56/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [56/100]. Skipping EarlyStopping check.\n",
      "Epoch [57/150] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [57/100]. Skipping EarlyStopping check.\n",
      "Epoch [58/150] | Train Loss: 0.0040 | Val Loss: 0.0002\n",
      "Warmup epoch [58/100]. Skipping EarlyStopping check.\n",
      "Epoch [59/150] | Train Loss: 0.0015 | Val Loss: 0.0002\n",
      "Warmup epoch [59/100]. Skipping EarlyStopping check.\n",
      "Epoch [60/150] | Train Loss: 0.0007 | Val Loss: 0.0001\n",
      "Warmup epoch [60/100]. Skipping EarlyStopping check.\n",
      "Epoch [61/150] | Train Loss: 0.0020 | Val Loss: 0.0129\n",
      "Warmup epoch [61/100]. Skipping EarlyStopping check.\n",
      "Epoch [62/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [62/100]. Skipping EarlyStopping check.\n",
      "Epoch [63/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [63/100]. Skipping EarlyStopping check.\n",
      "Epoch [64/150] | Train Loss: 0.0017 | Val Loss: 0.0000\n",
      "Warmup epoch [64/100]. Skipping EarlyStopping check.\n",
      "Epoch [65/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [65/100]. Skipping EarlyStopping check.\n",
      "Epoch [66/150] | Train Loss: 0.0016 | Val Loss: 0.0006\n",
      "Warmup epoch [66/100]. Skipping EarlyStopping check.\n",
      "Epoch [67/150] | Train Loss: 0.0011 | Val Loss: 0.0002\n",
      "Warmup epoch [67/100]. Skipping EarlyStopping check.\n",
      "Epoch [68/150] | Train Loss: 0.0008 | Val Loss: 0.0000\n",
      "Warmup epoch [68/100]. Skipping EarlyStopping check.\n",
      "Epoch [69/150] | Train Loss: 0.0010 | Val Loss: 0.0001\n",
      "Warmup epoch [69/100]. Skipping EarlyStopping check.\n",
      "Epoch [70/150] | Train Loss: 0.0008 | Val Loss: 0.0001\n",
      "Warmup epoch [70/100]. Skipping EarlyStopping check.\n",
      "Epoch [71/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [71/100]. Skipping EarlyStopping check.\n",
      "Epoch [72/150] | Train Loss: 0.0017 | Val Loss: 0.0000\n",
      "Warmup epoch [72/100]. Skipping EarlyStopping check.\n",
      "Epoch [73/150] | Train Loss: 0.0009 | Val Loss: 0.0001\n",
      "Warmup epoch [73/100]. Skipping EarlyStopping check.\n",
      "Epoch [74/150] | Train Loss: 0.0024 | Val Loss: 0.0001\n",
      "Warmup epoch [74/100]. Skipping EarlyStopping check.\n",
      "Epoch [75/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [75/100]. Skipping EarlyStopping check.\n",
      "Epoch [76/150] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "Warmup epoch [76/100]. Skipping EarlyStopping check.\n",
      "Epoch [77/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [77/100]. Skipping EarlyStopping check.\n",
      "Epoch [78/150] | Train Loss: 0.0010 | Val Loss: 0.0001\n",
      "Warmup epoch [78/100]. Skipping EarlyStopping check.\n",
      "Epoch [79/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [79/100]. Skipping EarlyStopping check.\n",
      "Epoch [80/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [80/100]. Skipping EarlyStopping check.\n",
      "Epoch [81/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [81/100]. Skipping EarlyStopping check.\n",
      "Epoch [82/150] | Train Loss: 0.0028 | Val Loss: 0.0000\n",
      "Warmup epoch [82/100]. Skipping EarlyStopping check.\n",
      "Epoch [83/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [83/100]. Skipping EarlyStopping check.\n",
      "Epoch [84/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [84/100]. Skipping EarlyStopping check.\n",
      "Epoch [85/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [85/100]. Skipping EarlyStopping check.\n",
      "Epoch [86/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [86/100]. Skipping EarlyStopping check.\n",
      "Epoch [87/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [87/100]. Skipping EarlyStopping check.\n",
      "Epoch [88/150] | Train Loss: 0.0027 | Val Loss: 0.0001\n",
      "Warmup epoch [88/100]. Skipping EarlyStopping check.\n",
      "Epoch [89/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [89/100]. Skipping EarlyStopping check.\n",
      "Epoch [90/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [90/100]. Skipping EarlyStopping check.\n",
      "Epoch [91/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [91/100]. Skipping EarlyStopping check.\n",
      "Epoch [92/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [92/100]. Skipping EarlyStopping check.\n",
      "Epoch [93/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [93/100]. Skipping EarlyStopping check.\n",
      "Epoch [94/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [94/100]. Skipping EarlyStopping check.\n",
      "Epoch [95/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [95/100]. Skipping EarlyStopping check.\n",
      "Epoch [96/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [96/100]. Skipping EarlyStopping check.\n",
      "Epoch [97/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [97/100]. Skipping EarlyStopping check.\n",
      "Epoch [98/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [98/100]. Skipping EarlyStopping check.\n",
      "Epoch [99/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [99/100]. Skipping EarlyStopping check.\n",
      "Epoch [100/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Warmup epoch [100/100]. Skipping EarlyStopping check.\n",
      "Epoch [101/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (inf --> 0.000007).  Saving model ...\n",
      "Epoch [102/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000006).  Saving model ...\n",
      "Epoch [103/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [104/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000005).  Saving model ...\n",
      "Epoch [105/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [106/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [107/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000004).  Saving model ...\n",
      "Epoch [108/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [109/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [110/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [111/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [112/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [113/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [114/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000004).  Saving model ...\n",
      "Epoch [115/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000004 --> 0.000003).  Saving model ...\n",
      "Epoch [116/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [117/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [118/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [119/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [120/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [121/150] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [122/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [123/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 8 out of 15\n",
      "Epoch [124/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 9 out of 15\n",
      "Epoch [125/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 10 out of 15\n",
      "Epoch [126/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 11 out of 15\n",
      "Epoch [127/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 12 out of 15\n",
      "Epoch [128/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 13 out of 15\n",
      "Epoch [129/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 14 out of 15\n",
      "Epoch [130/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 15 out of 15\n",
      "Early stopping triggered\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.0000\n",
      "Confusion Matrix:\n",
      "[[635   0]\n",
      " [  0 865]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000       635\n",
      "           1    1.00000   1.00000   1.00000       865\n",
      "\n",
      "    accuracy                        1.00000      1500\n",
      "   macro avg    1.00000   1.00000   1.00000      1500\n",
      "weighted avg    1.00000   1.00000   1.00000      1500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00000, Precision: 1.00000, Recall: 1.00000, F1: 1.00000, ROC AUC: 1.00000, AUPR (PR-AUC): 1.00000, Sensitivity: 1.00000, Specificity: 1.00000, Far: 0.0, False Positive Rate (FPR): 0.00000, False Negative Rate (FNR): 0.00000, Runtime: 0.037 sec , Memory Usage: 611.45 MB\n",
      "=========== SEED: 1234 , FOLD: 3/4, D: cpu ===========\n",
      " Label\n",
      "1    5722\n",
      "0    4278\n",
      "Name: count, dtype: int64\n",
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/150] | Train Loss: 0.4250 | Val Loss: 0.0438\n",
      "Warmup epoch [1/100]. Skipping EarlyStopping check.\n",
      "Epoch [2/150] | Train Loss: 0.0457 | Val Loss: 0.0229\n",
      "Warmup epoch [2/100]. Skipping EarlyStopping check.\n",
      "Epoch [3/150] | Train Loss: 0.0352 | Val Loss: 0.0385\n",
      "Warmup epoch [3/100]. Skipping EarlyStopping check.\n",
      "Epoch [4/150] | Train Loss: 0.0352 | Val Loss: 0.0175\n",
      "Warmup epoch [4/100]. Skipping EarlyStopping check.\n",
      "Epoch [5/150] | Train Loss: 0.0295 | Val Loss: 0.0158\n",
      "Warmup epoch [5/100]. Skipping EarlyStopping check.\n",
      "Epoch [6/150] | Train Loss: 0.0253 | Val Loss: 0.0126\n",
      "Warmup epoch [6/100]. Skipping EarlyStopping check.\n",
      "Epoch [7/150] | Train Loss: 0.0228 | Val Loss: 0.0139\n",
      "Warmup epoch [7/100]. Skipping EarlyStopping check.\n",
      "Epoch [8/150] | Train Loss: 0.0205 | Val Loss: 0.0084\n",
      "Warmup epoch [8/100]. Skipping EarlyStopping check.\n",
      "Epoch [9/150] | Train Loss: 0.0175 | Val Loss: 0.0071\n",
      "Warmup epoch [9/100]. Skipping EarlyStopping check.\n",
      "Epoch [10/150] | Train Loss: 0.0170 | Val Loss: 0.0056\n",
      "Warmup epoch [10/100]. Skipping EarlyStopping check.\n",
      "Epoch [11/150] | Train Loss: 0.0159 | Val Loss: 0.0066\n",
      "Warmup epoch [11/100]. Skipping EarlyStopping check.\n",
      "Epoch [12/150] | Train Loss: 0.0172 | Val Loss: 0.0048\n",
      "Warmup epoch [12/100]. Skipping EarlyStopping check.\n",
      "Epoch [13/150] | Train Loss: 0.0132 | Val Loss: 0.0033\n",
      "Warmup epoch [13/100]. Skipping EarlyStopping check.\n",
      "Epoch [14/150] | Train Loss: 0.0116 | Val Loss: 0.0024\n",
      "Warmup epoch [14/100]. Skipping EarlyStopping check.\n",
      "Epoch [15/150] | Train Loss: 0.0124 | Val Loss: 0.0024\n",
      "Warmup epoch [15/100]. Skipping EarlyStopping check.\n",
      "Epoch [16/150] | Train Loss: 0.0101 | Val Loss: 0.0032\n",
      "Warmup epoch [16/100]. Skipping EarlyStopping check.\n",
      "Epoch [17/150] | Train Loss: 0.0108 | Val Loss: 0.0022\n",
      "Warmup epoch [17/100]. Skipping EarlyStopping check.\n",
      "Epoch [18/150] | Train Loss: 0.0080 | Val Loss: 0.0009\n",
      "Warmup epoch [18/100]. Skipping EarlyStopping check.\n",
      "Epoch [19/150] | Train Loss: 0.0106 | Val Loss: 0.0016\n",
      "Warmup epoch [19/100]. Skipping EarlyStopping check.\n",
      "Epoch [20/150] | Train Loss: 0.0072 | Val Loss: 0.0010\n",
      "Warmup epoch [20/100]. Skipping EarlyStopping check.\n",
      "Epoch [21/150] | Train Loss: 0.0064 | Val Loss: 0.0013\n",
      "Warmup epoch [21/100]. Skipping EarlyStopping check.\n",
      "Epoch [22/150] | Train Loss: 0.0073 | Val Loss: 0.0022\n",
      "Warmup epoch [22/100]. Skipping EarlyStopping check.\n",
      "Epoch [23/150] | Train Loss: 0.0052 | Val Loss: 0.0006\n",
      "Warmup epoch [23/100]. Skipping EarlyStopping check.\n",
      "Epoch [24/150] | Train Loss: 0.0072 | Val Loss: 0.0006\n",
      "Warmup epoch [24/100]. Skipping EarlyStopping check.\n",
      "Epoch [25/150] | Train Loss: 0.0063 | Val Loss: 0.0033\n",
      "Warmup epoch [25/100]. Skipping EarlyStopping check.\n",
      "Epoch [26/150] | Train Loss: 0.0050 | Val Loss: 0.0012\n",
      "Warmup epoch [26/100]. Skipping EarlyStopping check.\n",
      "Epoch [27/150] | Train Loss: 0.0071 | Val Loss: 0.0005\n",
      "Warmup epoch [27/100]. Skipping EarlyStopping check.\n",
      "Epoch [28/150] | Train Loss: 0.0050 | Val Loss: 0.0033\n",
      "Warmup epoch [28/100]. Skipping EarlyStopping check.\n",
      "Epoch [29/150] | Train Loss: 0.0068 | Val Loss: 0.0011\n",
      "Warmup epoch [29/100]. Skipping EarlyStopping check.\n",
      "Epoch [30/150] | Train Loss: 0.0052 | Val Loss: 0.0003\n",
      "Warmup epoch [30/100]. Skipping EarlyStopping check.\n",
      "Epoch [31/150] | Train Loss: 0.0048 | Val Loss: 0.0005\n",
      "Warmup epoch [31/100]. Skipping EarlyStopping check.\n",
      "Epoch [32/150] | Train Loss: 0.0044 | Val Loss: 0.0005\n",
      "Warmup epoch [32/100]. Skipping EarlyStopping check.\n",
      "Epoch [33/150] | Train Loss: 0.0040 | Val Loss: 0.0004\n",
      "Warmup epoch [33/100]. Skipping EarlyStopping check.\n",
      "Epoch [34/150] | Train Loss: 0.0035 | Val Loss: 0.0003\n",
      "Warmup epoch [34/100]. Skipping EarlyStopping check.\n",
      "Epoch [35/150] | Train Loss: 0.0043 | Val Loss: 0.0004\n",
      "Warmup epoch [35/100]. Skipping EarlyStopping check.\n",
      "Epoch [36/150] | Train Loss: 0.0032 | Val Loss: 0.0002\n",
      "Warmup epoch [36/100]. Skipping EarlyStopping check.\n",
      "Epoch [37/150] | Train Loss: 0.0042 | Val Loss: 0.0002\n",
      "Warmup epoch [37/100]. Skipping EarlyStopping check.\n",
      "Epoch [38/150] | Train Loss: 0.0043 | Val Loss: 0.0003\n",
      "Warmup epoch [38/100]. Skipping EarlyStopping check.\n",
      "Epoch [39/150] | Train Loss: 0.0040 | Val Loss: 0.0002\n",
      "Warmup epoch [39/100]. Skipping EarlyStopping check.\n",
      "Epoch [40/150] | Train Loss: 0.0101 | Val Loss: 0.0018\n",
      "Warmup epoch [40/100]. Skipping EarlyStopping check.\n",
      "Epoch [41/150] | Train Loss: 0.0056 | Val Loss: 0.0008\n",
      "Warmup epoch [41/100]. Skipping EarlyStopping check.\n",
      "Epoch [42/150] | Train Loss: 0.0039 | Val Loss: 0.0002\n",
      "Warmup epoch [42/100]. Skipping EarlyStopping check.\n",
      "Epoch [43/150] | Train Loss: 0.0034 | Val Loss: 0.0003\n",
      "Warmup epoch [43/100]. Skipping EarlyStopping check.\n",
      "Epoch [44/150] | Train Loss: 0.0032 | Val Loss: 0.0004\n",
      "Warmup epoch [44/100]. Skipping EarlyStopping check.\n",
      "Epoch [45/150] | Train Loss: 0.0027 | Val Loss: 0.0002\n",
      "Warmup epoch [45/100]. Skipping EarlyStopping check.\n",
      "Epoch [46/150] | Train Loss: 0.0038 | Val Loss: 0.0003\n",
      "Warmup epoch [46/100]. Skipping EarlyStopping check.\n",
      "Epoch [47/150] | Train Loss: 0.0031 | Val Loss: 0.0015\n",
      "Warmup epoch [47/100]. Skipping EarlyStopping check.\n",
      "Epoch [48/150] | Train Loss: 0.0044 | Val Loss: 0.0009\n",
      "Warmup epoch [48/100]. Skipping EarlyStopping check.\n",
      "Epoch [49/150] | Train Loss: 0.0027 | Val Loss: 0.0004\n",
      "Warmup epoch [49/100]. Skipping EarlyStopping check.\n",
      "Epoch [50/150] | Train Loss: 0.0034 | Val Loss: 0.0002\n",
      "Warmup epoch [50/100]. Skipping EarlyStopping check.\n",
      "Epoch [51/150] | Train Loss: 0.0023 | Val Loss: 0.0003\n",
      "Warmup epoch [51/100]. Skipping EarlyStopping check.\n",
      "Epoch [52/150] | Train Loss: 0.0021 | Val Loss: 0.0001\n",
      "Warmup epoch [52/100]. Skipping EarlyStopping check.\n",
      "Epoch [53/150] | Train Loss: 0.0021 | Val Loss: 0.0001\n",
      "Warmup epoch [53/100]. Skipping EarlyStopping check.\n",
      "Epoch [54/150] | Train Loss: 0.0021 | Val Loss: 0.0002\n",
      "Warmup epoch [54/100]. Skipping EarlyStopping check.\n",
      "Epoch [55/150] | Train Loss: 0.0031 | Val Loss: 0.0002\n",
      "Warmup epoch [55/100]. Skipping EarlyStopping check.\n",
      "Epoch [56/150] | Train Loss: 0.0024 | Val Loss: 0.0002\n",
      "Warmup epoch [56/100]. Skipping EarlyStopping check.\n",
      "Epoch [57/150] | Train Loss: 0.0016 | Val Loss: 0.0002\n",
      "Warmup epoch [57/100]. Skipping EarlyStopping check.\n",
      "Epoch [58/150] | Train Loss: 0.0045 | Val Loss: 0.0003\n",
      "Warmup epoch [58/100]. Skipping EarlyStopping check.\n",
      "Epoch [59/150] | Train Loss: 0.0027 | Val Loss: 0.0004\n",
      "Warmup epoch [59/100]. Skipping EarlyStopping check.\n",
      "Epoch [60/150] | Train Loss: 0.0016 | Val Loss: 0.0002\n",
      "Warmup epoch [60/100]. Skipping EarlyStopping check.\n",
      "Epoch [61/150] | Train Loss: 0.0018 | Val Loss: 0.0002\n",
      "Warmup epoch [61/100]. Skipping EarlyStopping check.\n",
      "Epoch [62/150] | Train Loss: 0.0020 | Val Loss: 0.0001\n",
      "Warmup epoch [62/100]. Skipping EarlyStopping check.\n",
      "Epoch [63/150] | Train Loss: 0.0019 | Val Loss: 0.0002\n",
      "Warmup epoch [63/100]. Skipping EarlyStopping check.\n",
      "Epoch [64/150] | Train Loss: 0.0018 | Val Loss: 0.0001\n",
      "Warmup epoch [64/100]. Skipping EarlyStopping check.\n",
      "Epoch [65/150] | Train Loss: 0.0018 | Val Loss: 0.0003\n",
      "Warmup epoch [65/100]. Skipping EarlyStopping check.\n",
      "Epoch [66/150] | Train Loss: 0.0008 | Val Loss: 0.0001\n",
      "Warmup epoch [66/100]. Skipping EarlyStopping check.\n",
      "Epoch [67/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [67/100]. Skipping EarlyStopping check.\n",
      "Epoch [68/150] | Train Loss: 0.0009 | Val Loss: 0.0000\n",
      "Warmup epoch [68/100]. Skipping EarlyStopping check.\n",
      "Epoch [69/150] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [69/100]. Skipping EarlyStopping check.\n",
      "Epoch [70/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [70/100]. Skipping EarlyStopping check.\n",
      "Epoch [71/150] | Train Loss: 0.0009 | Val Loss: 0.0000\n",
      "Warmup epoch [71/100]. Skipping EarlyStopping check.\n",
      "Epoch [72/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [72/100]. Skipping EarlyStopping check.\n",
      "Epoch [73/150] | Train Loss: 0.0008 | Val Loss: 0.0000\n",
      "Warmup epoch [73/100]. Skipping EarlyStopping check.\n",
      "Epoch [74/150] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [74/100]. Skipping EarlyStopping check.\n",
      "Epoch [75/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [75/100]. Skipping EarlyStopping check.\n",
      "Epoch [76/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [76/100]. Skipping EarlyStopping check.\n",
      "Epoch [77/150] | Train Loss: 0.0003 | Val Loss: 0.0001\n",
      "Warmup epoch [77/100]. Skipping EarlyStopping check.\n",
      "Epoch [78/150] | Train Loss: 0.0012 | Val Loss: 0.0000\n",
      "Warmup epoch [78/100]. Skipping EarlyStopping check.\n",
      "Epoch [79/150] | Train Loss: 0.0024 | Val Loss: 0.0001\n",
      "Warmup epoch [79/100]. Skipping EarlyStopping check.\n",
      "Epoch [80/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Warmup epoch [80/100]. Skipping EarlyStopping check.\n",
      "Epoch [81/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Warmup epoch [81/100]. Skipping EarlyStopping check.\n",
      "Epoch [82/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [82/100]. Skipping EarlyStopping check.\n",
      "Epoch [83/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [83/100]. Skipping EarlyStopping check.\n",
      "Epoch [84/150] | Train Loss: 0.0006 | Val Loss: 0.0001\n",
      "Warmup epoch [84/100]. Skipping EarlyStopping check.\n",
      "Epoch [85/150] | Train Loss: 0.0018 | Val Loss: 0.0000\n",
      "Warmup epoch [85/100]. Skipping EarlyStopping check.\n",
      "Epoch [86/150] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [86/100]. Skipping EarlyStopping check.\n",
      "Epoch [87/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [87/100]. Skipping EarlyStopping check.\n",
      "Epoch [88/150] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "Warmup epoch [88/100]. Skipping EarlyStopping check.\n",
      "Epoch [89/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Warmup epoch [89/100]. Skipping EarlyStopping check.\n",
      "Epoch [90/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [90/100]. Skipping EarlyStopping check.\n",
      "Epoch [91/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [91/100]. Skipping EarlyStopping check.\n",
      "Epoch [92/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [92/100]. Skipping EarlyStopping check.\n",
      "Epoch [93/150] | Train Loss: 0.0007 | Val Loss: 0.0000\n",
      "Warmup epoch [93/100]. Skipping EarlyStopping check.\n",
      "Epoch [94/150] | Train Loss: 0.0009 | Val Loss: 0.0000\n",
      "Warmup epoch [94/100]. Skipping EarlyStopping check.\n",
      "Epoch [95/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Warmup epoch [95/100]. Skipping EarlyStopping check.\n",
      "Epoch [96/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [96/100]. Skipping EarlyStopping check.\n",
      "Epoch [97/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [97/100]. Skipping EarlyStopping check.\n",
      "Epoch [98/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Warmup epoch [98/100]. Skipping EarlyStopping check.\n",
      "Epoch [99/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [99/100]. Skipping EarlyStopping check.\n",
      "Epoch [100/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [100/100]. Skipping EarlyStopping check.\n",
      "Epoch [101/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (inf --> 0.000012).  Saving model ...\n",
      "Epoch [102/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000012 --> 0.000011).  Saving model ...\n",
      "Epoch [103/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000011).  Saving model ...\n",
      "Epoch [104/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000010).  Saving model ...\n",
      "Epoch [105/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [106/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [107/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000009).  Saving model ...\n",
      "Epoch [108/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000009 --> 0.000009).  Saving model ...\n",
      "Epoch [109/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [110/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000009 --> 0.000008).  Saving model ...\n",
      "Epoch [111/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000008 --> 0.000008).  Saving model ...\n",
      "Epoch [112/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000008 --> 0.000008).  Saving model ...\n",
      "Epoch [113/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000008 --> 0.000007).  Saving model ...\n",
      "Epoch [114/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [115/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000007).  Saving model ...\n",
      "Epoch [116/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000007).  Saving model ...\n",
      "Epoch [117/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000007).  Saving model ...\n",
      "Epoch [118/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000007).  Saving model ...\n",
      "Epoch [119/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000007).  Saving model ...\n",
      "Epoch [120/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000007 --> 0.000006).  Saving model ...\n",
      "Epoch [121/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [122/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [123/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [124/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [125/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [126/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [127/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [128/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000006).  Saving model ...\n",
      "Epoch [129/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000006 --> 0.000005).  Saving model ...\n",
      "Epoch [130/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [131/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [132/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [133/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [134/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [135/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [136/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [137/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [138/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [139/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [140/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [141/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [142/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [143/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [144/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [145/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [146/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [147/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [148/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [149/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Epoch [150/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000005 --> 0.000005).  Saving model ...\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.0000\n",
      "Confusion Matrix:\n",
      "[[652   0]\n",
      " [  0 848]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000       652\n",
      "           1    1.00000   1.00000   1.00000       848\n",
      "\n",
      "    accuracy                        1.00000      1500\n",
      "   macro avg    1.00000   1.00000   1.00000      1500\n",
      "weighted avg    1.00000   1.00000   1.00000      1500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00000, Precision: 1.00000, Recall: 1.00000, F1: 1.00000, ROC AUC: 1.00000, AUPR (PR-AUC): 1.00000, Sensitivity: 1.00000, Specificity: 1.00000, Far: 0.0, False Positive Rate (FPR): 0.00000, False Negative Rate (FNR): 0.00000, Runtime: 0.038 sec , Memory Usage: 513.44 MB\n",
      "=========== SEED: 2025 , FOLD: 4/4, D: cpu ===========\n",
      " Label\n",
      "1    5551\n",
      "0    4449\n",
      "Name: count, dtype: int64\n",
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/150] | Train Loss: 0.3850 | Val Loss: 0.0444\n",
      "Warmup epoch [1/100]. Skipping EarlyStopping check.\n",
      "Epoch [2/150] | Train Loss: 0.0547 | Val Loss: 0.0291\n",
      "Warmup epoch [2/100]. Skipping EarlyStopping check.\n",
      "Epoch [3/150] | Train Loss: 0.0373 | Val Loss: 0.0189\n",
      "Warmup epoch [3/100]. Skipping EarlyStopping check.\n",
      "Epoch [4/150] | Train Loss: 0.0325 | Val Loss: 0.0425\n",
      "Warmup epoch [4/100]. Skipping EarlyStopping check.\n",
      "Epoch [5/150] | Train Loss: 0.0340 | Val Loss: 0.0136\n",
      "Warmup epoch [5/100]. Skipping EarlyStopping check.\n",
      "Epoch [6/150] | Train Loss: 0.0347 | Val Loss: 0.0138\n",
      "Warmup epoch [6/100]. Skipping EarlyStopping check.\n",
      "Epoch [7/150] | Train Loss: 0.0305 | Val Loss: 0.0153\n",
      "Warmup epoch [7/100]. Skipping EarlyStopping check.\n",
      "Epoch [8/150] | Train Loss: 0.0297 | Val Loss: 0.0134\n",
      "Warmup epoch [8/100]. Skipping EarlyStopping check.\n",
      "Epoch [9/150] | Train Loss: 0.0258 | Val Loss: 0.0134\n",
      "Warmup epoch [9/100]. Skipping EarlyStopping check.\n",
      "Epoch [10/150] | Train Loss: 0.0229 | Val Loss: 0.0137\n",
      "Warmup epoch [10/100]. Skipping EarlyStopping check.\n",
      "Epoch [11/150] | Train Loss: 0.0203 | Val Loss: 0.0108\n",
      "Warmup epoch [11/100]. Skipping EarlyStopping check.\n",
      "Epoch [12/150] | Train Loss: 0.0173 | Val Loss: 0.0091\n",
      "Warmup epoch [12/100]. Skipping EarlyStopping check.\n",
      "Epoch [13/150] | Train Loss: 0.0177 | Val Loss: 0.0084\n",
      "Warmup epoch [13/100]. Skipping EarlyStopping check.\n",
      "Epoch [14/150] | Train Loss: 0.0166 | Val Loss: 0.0070\n",
      "Warmup epoch [14/100]. Skipping EarlyStopping check.\n",
      "Epoch [15/150] | Train Loss: 0.0185 | Val Loss: 0.0110\n",
      "Warmup epoch [15/100]. Skipping EarlyStopping check.\n",
      "Epoch [16/150] | Train Loss: 0.0147 | Val Loss: 0.0090\n",
      "Warmup epoch [16/100]. Skipping EarlyStopping check.\n",
      "Epoch [17/150] | Train Loss: 0.0143 | Val Loss: 0.0070\n",
      "Warmup epoch [17/100]. Skipping EarlyStopping check.\n",
      "Epoch [18/150] | Train Loss: 0.0145 | Val Loss: 0.0055\n",
      "Warmup epoch [18/100]. Skipping EarlyStopping check.\n",
      "Epoch [19/150] | Train Loss: 0.0140 | Val Loss: 0.0062\n",
      "Warmup epoch [19/100]. Skipping EarlyStopping check.\n",
      "Epoch [20/150] | Train Loss: 0.0131 | Val Loss: 0.0057\n",
      "Warmup epoch [20/100]. Skipping EarlyStopping check.\n",
      "Epoch [21/150] | Train Loss: 0.0124 | Val Loss: 0.0058\n",
      "Warmup epoch [21/100]. Skipping EarlyStopping check.\n",
      "Epoch [22/150] | Train Loss: 0.0104 | Val Loss: 0.0051\n",
      "Warmup epoch [22/100]. Skipping EarlyStopping check.\n",
      "Epoch [23/150] | Train Loss: 0.0105 | Val Loss: 0.0050\n",
      "Warmup epoch [23/100]. Skipping EarlyStopping check.\n",
      "Epoch [24/150] | Train Loss: 0.0122 | Val Loss: 0.0072\n",
      "Warmup epoch [24/100]. Skipping EarlyStopping check.\n",
      "Epoch [25/150] | Train Loss: 0.0101 | Val Loss: 0.0047\n",
      "Warmup epoch [25/100]. Skipping EarlyStopping check.\n",
      "Epoch [26/150] | Train Loss: 0.0101 | Val Loss: 0.0048\n",
      "Warmup epoch [26/100]. Skipping EarlyStopping check.\n",
      "Epoch [27/150] | Train Loss: 0.0073 | Val Loss: 0.0048\n",
      "Warmup epoch [27/100]. Skipping EarlyStopping check.\n",
      "Epoch [28/150] | Train Loss: 0.0069 | Val Loss: 0.0036\n",
      "Warmup epoch [28/100]. Skipping EarlyStopping check.\n",
      "Epoch [29/150] | Train Loss: 0.0135 | Val Loss: 0.0031\n",
      "Warmup epoch [29/100]. Skipping EarlyStopping check.\n",
      "Epoch [30/150] | Train Loss: 0.0066 | Val Loss: 0.0032\n",
      "Warmup epoch [30/100]. Skipping EarlyStopping check.\n",
      "Epoch [31/150] | Train Loss: 0.0076 | Val Loss: 0.0036\n",
      "Warmup epoch [31/100]. Skipping EarlyStopping check.\n",
      "Epoch [32/150] | Train Loss: 0.0065 | Val Loss: 0.0014\n",
      "Warmup epoch [32/100]. Skipping EarlyStopping check.\n",
      "Epoch [33/150] | Train Loss: 0.0063 | Val Loss: 0.0079\n",
      "Warmup epoch [33/100]. Skipping EarlyStopping check.\n",
      "Epoch [34/150] | Train Loss: 0.0071 | Val Loss: 0.0017\n",
      "Warmup epoch [34/100]. Skipping EarlyStopping check.\n",
      "Epoch [35/150] | Train Loss: 0.0053 | Val Loss: 0.0006\n",
      "Warmup epoch [35/100]. Skipping EarlyStopping check.\n",
      "Epoch [36/150] | Train Loss: 0.0058 | Val Loss: 0.0009\n",
      "Warmup epoch [36/100]. Skipping EarlyStopping check.\n",
      "Epoch [37/150] | Train Loss: 0.0061 | Val Loss: 0.0007\n",
      "Warmup epoch [37/100]. Skipping EarlyStopping check.\n",
      "Epoch [38/150] | Train Loss: 0.0045 | Val Loss: 0.0005\n",
      "Warmup epoch [38/100]. Skipping EarlyStopping check.\n",
      "Epoch [39/150] | Train Loss: 0.0055 | Val Loss: 0.0004\n",
      "Warmup epoch [39/100]. Skipping EarlyStopping check.\n",
      "Epoch [40/150] | Train Loss: 0.0058 | Val Loss: 0.0004\n",
      "Warmup epoch [40/100]. Skipping EarlyStopping check.\n",
      "Epoch [41/150] | Train Loss: 0.0069 | Val Loss: 0.0006\n",
      "Warmup epoch [41/100]. Skipping EarlyStopping check.\n",
      "Epoch [42/150] | Train Loss: 0.0069 | Val Loss: 0.0095\n",
      "Warmup epoch [42/100]. Skipping EarlyStopping check.\n",
      "Epoch [43/150] | Train Loss: 0.0063 | Val Loss: 0.0015\n",
      "Warmup epoch [43/100]. Skipping EarlyStopping check.\n",
      "Epoch [44/150] | Train Loss: 0.0049 | Val Loss: 0.0040\n",
      "Warmup epoch [44/100]. Skipping EarlyStopping check.\n",
      "Epoch [45/150] | Train Loss: 0.0064 | Val Loss: 0.0009\n",
      "Warmup epoch [45/100]. Skipping EarlyStopping check.\n",
      "Epoch [46/150] | Train Loss: 0.0046 | Val Loss: 0.0004\n",
      "Warmup epoch [46/100]. Skipping EarlyStopping check.\n",
      "Epoch [47/150] | Train Loss: 0.0059 | Val Loss: 0.0004\n",
      "Warmup epoch [47/100]. Skipping EarlyStopping check.\n",
      "Epoch [48/150] | Train Loss: 0.0050 | Val Loss: 0.0003\n",
      "Warmup epoch [48/100]. Skipping EarlyStopping check.\n",
      "Epoch [49/150] | Train Loss: 0.0046 | Val Loss: 0.0013\n",
      "Warmup epoch [49/100]. Skipping EarlyStopping check.\n",
      "Epoch [50/150] | Train Loss: 0.0035 | Val Loss: 0.0005\n",
      "Warmup epoch [50/100]. Skipping EarlyStopping check.\n",
      "Epoch [51/150] | Train Loss: 0.0049 | Val Loss: 0.0004\n",
      "Warmup epoch [51/100]. Skipping EarlyStopping check.\n",
      "Epoch [52/150] | Train Loss: 0.0047 | Val Loss: 0.0004\n",
      "Warmup epoch [52/100]. Skipping EarlyStopping check.\n",
      "Epoch [53/150] | Train Loss: 0.0042 | Val Loss: 0.0004\n",
      "Warmup epoch [53/100]. Skipping EarlyStopping check.\n",
      "Epoch [54/150] | Train Loss: 0.0034 | Val Loss: 0.0003\n",
      "Warmup epoch [54/100]. Skipping EarlyStopping check.\n",
      "Epoch [55/150] | Train Loss: 0.0041 | Val Loss: 0.0006\n",
      "Warmup epoch [55/100]. Skipping EarlyStopping check.\n",
      "Epoch [56/150] | Train Loss: 0.0035 | Val Loss: 0.0003\n",
      "Warmup epoch [56/100]. Skipping EarlyStopping check.\n",
      "Epoch [57/150] | Train Loss: 0.0032 | Val Loss: 0.0044\n",
      "Warmup epoch [57/100]. Skipping EarlyStopping check.\n",
      "Epoch [58/150] | Train Loss: 0.0051 | Val Loss: 0.0010\n",
      "Warmup epoch [58/100]. Skipping EarlyStopping check.\n",
      "Epoch [59/150] | Train Loss: 0.0041 | Val Loss: 0.0005\n",
      "Warmup epoch [59/100]. Skipping EarlyStopping check.\n",
      "Epoch [60/150] | Train Loss: 0.0036 | Val Loss: 0.0004\n",
      "Warmup epoch [60/100]. Skipping EarlyStopping check.\n",
      "Epoch [61/150] | Train Loss: 0.0038 | Val Loss: 0.0002\n",
      "Warmup epoch [61/100]. Skipping EarlyStopping check.\n",
      "Epoch [62/150] | Train Loss: 0.0039 | Val Loss: 0.0002\n",
      "Warmup epoch [62/100]. Skipping EarlyStopping check.\n",
      "Epoch [63/150] | Train Loss: 0.0031 | Val Loss: 0.0007\n",
      "Warmup epoch [63/100]. Skipping EarlyStopping check.\n",
      "Epoch [64/150] | Train Loss: 0.0030 | Val Loss: 0.0003\n",
      "Warmup epoch [64/100]. Skipping EarlyStopping check.\n",
      "Epoch [65/150] | Train Loss: 0.0032 | Val Loss: 0.0005\n",
      "Warmup epoch [65/100]. Skipping EarlyStopping check.\n",
      "Epoch [66/150] | Train Loss: 0.0032 | Val Loss: 0.0003\n",
      "Warmup epoch [66/100]. Skipping EarlyStopping check.\n",
      "Epoch [67/150] | Train Loss: 0.0022 | Val Loss: 0.0002\n",
      "Warmup epoch [67/100]. Skipping EarlyStopping check.\n",
      "Epoch [68/150] | Train Loss: 0.0040 | Val Loss: 0.0001\n",
      "Warmup epoch [68/100]. Skipping EarlyStopping check.\n",
      "Epoch [69/150] | Train Loss: 0.0021 | Val Loss: 0.0001\n",
      "Warmup epoch [69/100]. Skipping EarlyStopping check.\n",
      "Epoch [70/150] | Train Loss: 0.0020 | Val Loss: 0.0036\n",
      "Warmup epoch [70/100]. Skipping EarlyStopping check.\n",
      "Epoch [71/150] | Train Loss: 0.0026 | Val Loss: 0.0001\n",
      "Warmup epoch [71/100]. Skipping EarlyStopping check.\n",
      "Epoch [72/150] | Train Loss: 0.0024 | Val Loss: 0.0001\n",
      "Warmup epoch [72/100]. Skipping EarlyStopping check.\n",
      "Epoch [73/150] | Train Loss: 0.0018 | Val Loss: 0.0007\n",
      "Warmup epoch [73/100]. Skipping EarlyStopping check.\n",
      "Epoch [74/150] | Train Loss: 0.0036 | Val Loss: 0.0002\n",
      "Warmup epoch [74/100]. Skipping EarlyStopping check.\n",
      "Epoch [75/150] | Train Loss: 0.0013 | Val Loss: 0.0001\n",
      "Warmup epoch [75/100]. Skipping EarlyStopping check.\n",
      "Epoch [76/150] | Train Loss: 0.0015 | Val Loss: 0.0001\n",
      "Warmup epoch [76/100]. Skipping EarlyStopping check.\n",
      "Epoch [77/150] | Train Loss: 0.0014 | Val Loss: 0.0001\n",
      "Warmup epoch [77/100]. Skipping EarlyStopping check.\n",
      "Epoch [78/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [78/100]. Skipping EarlyStopping check.\n",
      "Epoch [79/150] | Train Loss: 0.0005 | Val Loss: 0.0001\n",
      "Warmup epoch [79/100]. Skipping EarlyStopping check.\n",
      "Epoch [80/150] | Train Loss: 0.0064 | Val Loss: 0.0002\n",
      "Warmup epoch [80/100]. Skipping EarlyStopping check.\n",
      "Epoch [81/150] | Train Loss: 0.0019 | Val Loss: 0.0001\n",
      "Warmup epoch [81/100]. Skipping EarlyStopping check.\n",
      "Epoch [82/150] | Train Loss: 0.0009 | Val Loss: 0.0003\n",
      "Warmup epoch [82/100]. Skipping EarlyStopping check.\n",
      "Epoch [83/150] | Train Loss: 0.0012 | Val Loss: 0.0001\n",
      "Warmup epoch [83/100]. Skipping EarlyStopping check.\n",
      "Epoch [84/150] | Train Loss: 0.0009 | Val Loss: 0.0001\n",
      "Warmup epoch [84/100]. Skipping EarlyStopping check.\n",
      "Epoch [85/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [85/100]. Skipping EarlyStopping check.\n",
      "Epoch [86/150] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "Warmup epoch [86/100]. Skipping EarlyStopping check.\n",
      "Epoch [87/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Warmup epoch [87/100]. Skipping EarlyStopping check.\n",
      "Epoch [88/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [88/100]. Skipping EarlyStopping check.\n",
      "Epoch [89/150] | Train Loss: 0.0002 | Val Loss: 0.0001\n",
      "Warmup epoch [89/100]. Skipping EarlyStopping check.\n",
      "Epoch [90/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "Warmup epoch [90/100]. Skipping EarlyStopping check.\n",
      "Epoch [91/150] | Train Loss: 0.0013 | Val Loss: 0.0000\n",
      "Warmup epoch [91/100]. Skipping EarlyStopping check.\n",
      "Epoch [92/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [92/100]. Skipping EarlyStopping check.\n",
      "Epoch [93/150] | Train Loss: 0.0014 | Val Loss: 0.0001\n",
      "Warmup epoch [93/100]. Skipping EarlyStopping check.\n",
      "Epoch [94/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [94/100]. Skipping EarlyStopping check.\n",
      "Epoch [95/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [95/100]. Skipping EarlyStopping check.\n",
      "Epoch [96/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "Warmup epoch [96/100]. Skipping EarlyStopping check.\n",
      "Epoch [97/150] | Train Loss: 0.0006 | Val Loss: 0.0000\n",
      "Warmup epoch [97/100]. Skipping EarlyStopping check.\n",
      "Epoch [98/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [98/100]. Skipping EarlyStopping check.\n",
      "Epoch [99/150] | Train Loss: 0.0013 | Val Loss: 0.0002\n",
      "Warmup epoch [99/100]. Skipping EarlyStopping check.\n",
      "Epoch [100/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Warmup epoch [100/100]. Skipping EarlyStopping check.\n",
      "Epoch [101/150] | Train Loss: 0.0004 | Val Loss: 0.0000\n",
      "Validation loss decreased (inf --> 0.000022).  Saving model ...\n",
      "Epoch [102/150] | Train Loss: 0.0009 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000022 --> 0.000018).  Saving model ...\n",
      "Epoch [103/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [104/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [105/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000018 --> 0.000018).  Saving model ...\n",
      "Epoch [106/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000018 --> 0.000017).  Saving model ...\n",
      "Epoch [107/150] | Train Loss: 0.0013 | Val Loss: 0.0001\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [108/150] | Train Loss: 0.0011 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [109/150] | Train Loss: 0.0013 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [110/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [111/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [112/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [113/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [114/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000017 --> 0.000016).  Saving model ...\n",
      "Epoch [115/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000016 --> 0.000015).  Saving model ...\n",
      "Epoch [116/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000015 --> 0.000015).  Saving model ...\n",
      "Epoch [117/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000015 --> 0.000014).  Saving model ...\n",
      "Epoch [118/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000014 --> 0.000014).  Saving model ...\n",
      "Epoch [119/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000014 --> 0.000013).  Saving model ...\n",
      "Epoch [120/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [121/150] | Train Loss: 0.0005 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000013 --> 0.000012).  Saving model ...\n",
      "Epoch [122/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [123/150] | Train Loss: 0.0003 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [124/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [125/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [126/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [127/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [128/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [129/150] | Train Loss: 0.0010 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000012 --> 0.000011).  Saving model ...\n",
      "Epoch [130/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000011).  Saving model ...\n",
      "Epoch [131/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000011).  Saving model ...\n",
      "Epoch [132/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000011).  Saving model ...\n",
      "Epoch [133/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000011).  Saving model ...\n",
      "Epoch [134/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [135/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000011 --> 0.000010).  Saving model ...\n",
      "Epoch [136/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [137/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [138/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [139/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [140/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Epoch [141/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 5 out of 15\n",
      "Epoch [142/150] | Train Loss: 0.0016 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 6 out of 15\n",
      "Epoch [143/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 7 out of 15\n",
      "Epoch [144/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [145/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [146/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "Validation loss decreased (0.000010 --> 0.000010).  Saving model ...\n",
      "Epoch [147/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 1 out of 15\n",
      "Epoch [148/150] | Train Loss: 0.0001 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 2 out of 15\n",
      "Epoch [149/150] | Train Loss: 0.0002 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 3 out of 15\n",
      "Epoch [150/150] | Train Loss: 0.0000 | Val Loss: 0.0000\n",
      "EarlyStopping counter: 4 out of 15\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.0000\n",
      "Confusion Matrix:\n",
      "[[631   0]\n",
      " [  0 869]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000       631\n",
      "           1    1.00000   1.00000   1.00000       869\n",
      "\n",
      "    accuracy                        1.00000      1500\n",
      "   macro avg    1.00000   1.00000   1.00000      1500\n",
      "weighted avg    1.00000   1.00000   1.00000      1500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00000, Precision: 1.00000, Recall: 1.00000, F1: 1.00000, ROC AUC: 1.00000, AUPR (PR-AUC): 1.00000, Sensitivity: 1.00000, Specificity: 1.00000, Far: 0.0, False Positive Rate (FPR): 0.00000, False Negative Rate (FNR): 0.00000, Runtime: 0.038 sec , Memory Usage: 428.90 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEEDlist = [28, 7, 1234, 2025]\n",
    "for i, SEED in enumerate(SEEDlist):\n",
    "    train_loader, val_loader, test_loader = None, None, None\n",
    "    print(f\"=========== SEED: {SEED} , FOLD: {i+1}/{len(SEEDlist)}, D: {device} ===========\")\n",
    "    random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    current_dir = \"Data/\"\n",
    "    df = pd.read_csv(os.path.join(current_dir, 'DDos.csv'))\n",
    "    encoder = LabelEncoder()\n",
    "    df[' Label'] = encoder.fit_transform(df[' Label'])\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna()\n",
    "    df = df.astype(int)\n",
    "    df = df.sample(n=10000, random_state=SEED, replace=False)\n",
    "    X = df.drop(' Label', axis=1)\n",
    "    y = df[' Label']\n",
    "    X.columns = X.columns.str.strip()\n",
    "    important_features = ['Bwd Packet Length Std', 'Average Packet Size', 'Flow Duration', 'Flow IAT Std']\n",
    "    important_df = X[important_features] * 2.0\n",
    "    remaining_df = X.drop(columns=important_features)\n",
    "    X = pd.concat([remaining_df, important_df], axis=1)\n",
    "    scaler = MinMaxScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    print(y.value_counts())\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    batch_size = 64\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    epochs = 150\n",
    "    SL = len(train_loader) * epochs\n",
    "    backbone_config = {\n",
    "        'type': 'MLP',\n",
    "        'n_blocks': 2,\n",
    "        'd_block': 32,\n",
    "        'dropout': 0.1,\n",
    "    }\n",
    "    tabm = Model(\n",
    "        n_num_features=78,\n",
    "        cat_cardinalities=[],\n",
    "        n_classes=78,\n",
    "        backbone=backbone_config,\n",
    "        num_embeddings=None,\n",
    "        arch_type='tabm',\n",
    "        bins=None,\n",
    "        k=8\n",
    "    )\n",
    "    model = MODEL(tabm=tabm).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=SL, eta_min=1e-5)\n",
    "    early_stopper = EarlyStopping(patience=15, verbose=True, path='best_model.pt', warmup_epochs=100)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"=========== TP: {total_params:,} ===========\")\n",
    "    best_model = train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        epochs=epochs,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        early_stopping=early_stopper\n",
    "    )\n",
    "    RES = test(best_model, test_loader)\n",
    "    print(RES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
