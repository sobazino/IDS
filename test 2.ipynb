{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600e1f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Literal, NamedTuple\n",
    "\n",
    "from TabM import Model, make_parameter_groups\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "import time\n",
    "import cpuinfo\n",
    "import torch\n",
    "import psutil\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import platform\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score, accuracy_score, roc_auc_score, precision_recall_curve, auc, f1_score, recall_score, precision_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bad24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def get_memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem = process.memory_info().rss / (1024 ** 2)\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "829db29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    start_time = time.time()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch).cpu().numpy()\n",
    "            preds = (outputs >= 0.5).astype(int)\n",
    "            all_predictions.extend(preds if preds.ndim == 1 else preds.tolist())\n",
    "            all_labels.extend(y_batch.cpu().numpy().tolist())\n",
    "\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    M = \"OK-\"\n",
    "    if len(set(all_predictions)) == 1:\n",
    "        M = \"ER-\"\n",
    "        \n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    false_positive_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    false_negative_rate = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "    roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "    aupr = average_precision_score(all_labels, all_predictions)\n",
    "    Far = fp / (fp + tn) if (fp + tn) != 0 else 0\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions, digits=5))\n",
    "    errors = [(i, p, l) for i, (p, l) in enumerate(zip(all_predictions, all_labels)) if p != l]\n",
    "    print(f\"Total Errors: {len(errors)}\")\n",
    "    for i, pred, label in errors[:5]:\n",
    "        print(f\"Index: {i}, Predicted: {pred}, Actual: {label}\")\n",
    "    memory_usage = get_memory_usage()\n",
    "    return f\"{M} Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1: {f1:.2f}, ROC AUC: {roc_auc:.2f}, AUPR (PR-AUC): {aupr:.2f}, Sensitivity: {sensitivity:.2f}, Specificity: {specificity:.2f}, Far: {Far}, False Positive Rate (FPR): {false_positive_rate:.2f}, False Negative Rate (FNR): {false_negative_rate:.2f}, Runtime: {elapsed_time:.2f} sec , Memory Usage: {memory_usage:.2f} MB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9629d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, scheduler, epochs, train_loader, val_loader, test_loader):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_idx, (X_train_batch, y_train_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(X_train_batch)\n",
    "            loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_loss_batch = 0\n",
    "                    for X_val_batch, y_val_batch in val_loader:\n",
    "                        outputs_val = model(X_val_batch)\n",
    "                        loss_val = criterion(outputs_val, y_val_batch.float())\n",
    "                        val_loss_batch += loss_val.item()\n",
    "                    train_loss_batch = 0\n",
    "                    for X_train_batch, y_train_batch in train_loader:\n",
    "                        outputs_train = model(X_train_batch)\n",
    "                        loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "                        train_loss_batch += loss_train.item()\n",
    "                        \n",
    "                    val_loss_avg = val_loss_batch / len(val_loader)\n",
    "                    train_loss_avg = train_loss_batch / len(train_loader)\n",
    "                \n",
    "                for param_group in optimizer.param_groups:\n",
    "                    lrnum = param_group['lr']\n",
    "                train_losses.append(train_loss_avg)\n",
    "                val_losses.append(val_loss_avg)\n",
    "                print(f'Epoch [{epoch+1}/{epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Train Loss: {loss_train.item():.4f}, Val Loss: {val_loss_avg:.4f}, LR: {lrnum:.10f}')\n",
    "                model.train()\n",
    "        \n",
    "        if test_loader and epoch % 10 == 0:\n",
    "            RES = test(model, test_loader)\n",
    "            print(f\"Epoch {epoch+1}: {RES}\")\n",
    "\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('loss.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "afd39380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', warmup_epochs=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "\n",
    "    def __call__(self, val_loss, model, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            if self.verbose:\n",
    "                print(f\"Warmup epoch [{epoch+1}/{self.warmup_epochs}]. Skipping EarlyStopping check.\")\n",
    "            return\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "def train(model, criterion, optimizer, scheduler, epochs, train_loader, val_loader, device, early_stopping):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for X_train_batch, y_train_batch in train_loader:\n",
    "            X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(X_train_batch)\n",
    "            loss_train = criterion(outputs_train, y_train_batch.float())\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "            running_train_loss += loss_train.item()\n",
    "\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val_batch, y_val_batch in val_loader:\n",
    "                X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "                outputs_val = model(X_val_batch)\n",
    "                loss_val = criterion(outputs_val, y_val_batch.float())\n",
    "                running_val_loss += loss_val.item()\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] | Train Loss: {epoch_train_loss:.2f} | Val Loss: {epoch_val_loss:.2f}')\n",
    "        early_stopping(epoch_val_loss, model, epoch)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    print(f\"Loading best model from '{early_stopping.path}' with validation loss: {early_stopping.val_loss_min:.2f}\")\n",
    "    model.load_state_dict(torch.load(early_stopping.path, weights_only=True))\n",
    "\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('loss_per_epoch.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8055abc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== D: cpu ===========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'=========== D: {device} ===========\\n')\n",
    "def GET(data):\n",
    "    train_loader, val_loader, test_loader = None, None, None\n",
    "    current_dir = \"Data/\"\n",
    "    df = pd.read_csv(os.path.join(current_dir, data))\n",
    "    df.columns = df.columns.str.strip()\n",
    "        \n",
    "    if data == 'cicddos2019.csv':\n",
    "        df = df.drop('Label', axis=1)\n",
    "        df = df.rename(columns={'Class': 'Label'})\n",
    "    \n",
    "    elif data == 'cicids2018.csv':\n",
    "        df['Label'] = df['Label'].apply(lambda x: 'Attack' if x != 'Benign' else 'Benign')\n",
    "        df = df.drop('Timestamp', axis=1)\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype == 'object':\n",
    "            df[column] = le.fit_transform(df[column])\n",
    "        \n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.dropna()\n",
    "    X = df.drop('Label', axis=1)\n",
    "    y = df['Label']\n",
    "    print(y.value_counts(), len(df.columns))\n",
    "        \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_val = np.array(X_val)\n",
    "    y_val = np.array(y_val)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(device)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "    \n",
    "    batch_size = 64\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "47ceddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MODEL(nn.Module):\n",
    "    def __init__(self, tabm):\n",
    "        super(MODEL, self).__init__()\n",
    "        self.tabm = tabm\n",
    "        self.C1 = nn.Conv1d(10, 16, 4)\n",
    "        self.C2 = nn.Conv1d(16, 16, 4)\n",
    "        self.C3 = nn.Conv1d(16, 16, 4)\n",
    "        self.pool = nn.MaxPool1d(3)\n",
    "        self.F1 = nn.Linear(16, 32)\n",
    "        self.F2 = nn.Linear(32, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.attn_weights = nn.Parameter(torch.randn(78))\n",
    "\n",
    "    def forward(self, x=None, x_cat=None):\n",
    "        t = self.tabm(x, x_cat)\n",
    "        attention = torch.matmul(x, self.attn_weights)\n",
    "        attention = torch.sigmoid(attention).unsqueeze(1)\n",
    "        y = (x * attention).unsqueeze(1)\n",
    "        \n",
    "        x = x.unsqueeze(1)\n",
    "        x = torch.cat((x, y, t), dim=1)\n",
    "        x = self.tanh(self.C1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tanh(self.C2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.tanh(self.C3(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x).squeeze(2)\n",
    "        x = self.tanh(self.F1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.sigmoid(self.F2(x)).squeeze(1)\n",
    "        return x\n",
    "\n",
    "backbone_config = {\n",
    "    'type': 'MLP',\n",
    "    'n_blocks': 2,\n",
    "    'd_block': 32,\n",
    "    'dropout': 0.1,\n",
    "}\n",
    "tabm = Model(\n",
    "    n_num_features=78,\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=78,\n",
    "    backbone=backbone_config,\n",
    "    num_embeddings=None,\n",
    "    arch_type='tabm',\n",
    "    bins=None,\n",
    "    k=8\n",
    ")\n",
    "\n",
    "model = MODEL(tabm=tabm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5a37b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(train_loader, val_loader, test_loader, warmup):\n",
    "    epochs = 200\n",
    "    SL = len(train_loader) * epochs\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=SL, eta_min=1e-5)\n",
    "    early_stopper = EarlyStopping(patience=30, verbose=True, path='best_model.pt', warmup_epochs=warmup)\n",
    "\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"=========== TP: {total_params:,} ===========\")\n",
    "    \n",
    "    best_model = train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        epochs=epochs,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        device=device,\n",
    "        early_stopping=early_stopper\n",
    "    )\n",
    "    RES = test(best_model, test_loader)\n",
    "    print(RES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b2520879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "0    38607\n",
      "1    11393\n",
      "Name: count, dtype: int64 79\n",
      "Label\n",
      "0    28774\n",
      "1    21226\n",
      "Name: count, dtype: int64 79\n"
     ]
    }
   ],
   "source": [
    "train_loader2019, val_loader2019, test_loader2019 = GET('cicddos2019.csv')\n",
    "train_loader2018, val_loader2018, test_loader2018 = GET('cicids2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cb9fc256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/200] | Train Loss: 0.11 | Val Loss: 0.02\n",
      "Warmup epoch [1/50]. Skipping EarlyStopping check.\n",
      "Epoch [2/200] | Train Loss: 0.03 | Val Loss: 0.02\n",
      "Warmup epoch [2/50]. Skipping EarlyStopping check.\n",
      "Epoch [3/200] | Train Loss: 0.02 | Val Loss: 0.02\n",
      "Warmup epoch [3/50]. Skipping EarlyStopping check.\n",
      "Epoch [4/200] | Train Loss: 0.02 | Val Loss: 0.02\n",
      "Warmup epoch [4/50]. Skipping EarlyStopping check.\n",
      "Epoch [5/200] | Train Loss: 0.02 | Val Loss: 0.02\n",
      "Warmup epoch [5/50]. Skipping EarlyStopping check.\n",
      "Epoch [6/200] | Train Loss: 0.02 | Val Loss: 0.01\n",
      "Warmup epoch [6/50]. Skipping EarlyStopping check.\n",
      "Epoch [7/200] | Train Loss: 0.02 | Val Loss: 0.01\n",
      "Warmup epoch [7/50]. Skipping EarlyStopping check.\n",
      "Epoch [8/200] | Train Loss: 0.02 | Val Loss: 0.01\n",
      "Warmup epoch [8/50]. Skipping EarlyStopping check.\n",
      "Epoch [9/200] | Train Loss: 0.02 | Val Loss: 0.01\n",
      "Warmup epoch [9/50]. Skipping EarlyStopping check.\n",
      "Epoch [10/200] | Train Loss: 0.02 | Val Loss: 0.01\n",
      "Warmup epoch [10/50]. Skipping EarlyStopping check.\n",
      "Epoch [11/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [11/50]. Skipping EarlyStopping check.\n",
      "Epoch [12/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [12/50]. Skipping EarlyStopping check.\n",
      "Epoch [13/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [13/50]. Skipping EarlyStopping check.\n",
      "Epoch [14/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [14/50]. Skipping EarlyStopping check.\n",
      "Epoch [15/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [15/50]. Skipping EarlyStopping check.\n",
      "Epoch [16/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [16/50]. Skipping EarlyStopping check.\n",
      "Epoch [17/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [17/50]. Skipping EarlyStopping check.\n",
      "Epoch [18/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [18/50]. Skipping EarlyStopping check.\n",
      "Epoch [19/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [19/50]. Skipping EarlyStopping check.\n",
      "Epoch [20/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [20/50]. Skipping EarlyStopping check.\n",
      "Epoch [21/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [21/50]. Skipping EarlyStopping check.\n",
      "Epoch [22/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [22/50]. Skipping EarlyStopping check.\n",
      "Epoch [23/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [23/50]. Skipping EarlyStopping check.\n",
      "Epoch [24/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [24/50]. Skipping EarlyStopping check.\n",
      "Epoch [25/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [25/50]. Skipping EarlyStopping check.\n",
      "Epoch [26/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [26/50]. Skipping EarlyStopping check.\n",
      "Epoch [27/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [27/50]. Skipping EarlyStopping check.\n",
      "Epoch [28/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [28/50]. Skipping EarlyStopping check.\n",
      "Epoch [29/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [29/50]. Skipping EarlyStopping check.\n",
      "Epoch [30/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [30/50]. Skipping EarlyStopping check.\n",
      "Epoch [31/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [31/50]. Skipping EarlyStopping check.\n",
      "Epoch [32/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [32/50]. Skipping EarlyStopping check.\n",
      "Epoch [33/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [33/50]. Skipping EarlyStopping check.\n",
      "Epoch [34/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [34/50]. Skipping EarlyStopping check.\n",
      "Epoch [35/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [35/50]. Skipping EarlyStopping check.\n",
      "Epoch [36/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [36/50]. Skipping EarlyStopping check.\n",
      "Epoch [37/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [37/50]. Skipping EarlyStopping check.\n",
      "Epoch [38/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [38/50]. Skipping EarlyStopping check.\n",
      "Epoch [39/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [39/50]. Skipping EarlyStopping check.\n",
      "Epoch [40/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [40/50]. Skipping EarlyStopping check.\n",
      "Epoch [41/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [41/50]. Skipping EarlyStopping check.\n",
      "Epoch [42/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [42/50]. Skipping EarlyStopping check.\n",
      "Epoch [43/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [43/50]. Skipping EarlyStopping check.\n",
      "Epoch [44/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [44/50]. Skipping EarlyStopping check.\n",
      "Epoch [45/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [45/50]. Skipping EarlyStopping check.\n",
      "Epoch [46/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [46/50]. Skipping EarlyStopping check.\n",
      "Epoch [47/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [47/50]. Skipping EarlyStopping check.\n",
      "Epoch [48/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [48/50]. Skipping EarlyStopping check.\n",
      "Epoch [49/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [49/50]. Skipping EarlyStopping check.\n",
      "Epoch [50/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Warmup epoch [50/50]. Skipping EarlyStopping check.\n",
      "Epoch [51/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Validation loss decreased (inf --> 0.008059).  Saving model ...\n",
      "Epoch [52/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [53/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [54/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Validation loss decreased (0.008059 --> 0.007380).  Saving model ...\n",
      "Epoch [55/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [56/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [57/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [58/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [59/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [60/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [61/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [62/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [63/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [64/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [65/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [66/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [67/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "Validation loss decreased (0.007380 --> 0.007167).  Saving model ...\n",
      "Epoch [68/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [69/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [70/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [71/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [72/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [73/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [74/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [75/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [76/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [77/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [78/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [79/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [80/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch [81/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch [82/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch [83/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch [84/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch [85/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch [86/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch [87/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch [88/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch [89/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch [90/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch [91/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch [92/200] | Train Loss: 0.00 | Val Loss: 0.01\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch [93/200] | Train Loss: 0.00 | Val Loss: 0.01\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch [94/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch [95/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch [96/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch [97/200] | Train Loss: 0.01 | Val Loss: 0.01\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping triggered\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.01\n",
      "Confusion Matrix:\n",
      "[[5812   22]\n",
      " [   1 1665]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.99983   0.99623   0.99803      5834\n",
      "           1    0.98696   0.99940   0.99314      1666\n",
      "\n",
      "    accuracy                        0.99693      7500\n",
      "   macro avg    0.99339   0.99781   0.99558      7500\n",
      "weighted avg    0.99697   0.99693   0.99694      7500\n",
      "\n",
      "Total Errors: 23\n",
      "Index: 224, Predicted: 1, Actual: 0\n",
      "Index: 454, Predicted: 1, Actual: 0\n",
      "Index: 675, Predicted: 1, Actual: 0\n",
      "Index: 726, Predicted: 1, Actual: 0\n",
      "Index: 1131, Predicted: 1, Actual: 0\n",
      "OK- Accuracy: 1.00, Precision: 0.99, Recall: 1.00, F1: 0.99, ROC AUC: 1.00, AUPR (PR-AUC): 0.99, Sensitivity: 1.00, Specificity: 1.00, Far: 0.0037709976002742542, False Positive Rate (FPR): 0.00, False Negative Rate (FNR): 0.00, Runtime: 0.19 sec , Memory Usage: 678.46 MB\n"
     ]
    }
   ],
   "source": [
    "start(train_loader2019, val_loader2019, test_loader2019, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "83254ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== TP: 29,407 ===========\n",
      "Epoch [1/200] | Train Loss: 0.07 | Val Loss: 0.00\n",
      "Warmup epoch [1/1]. Skipping EarlyStopping check.\n",
      "Epoch [2/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (inf --> 0.001588).  Saving model ...\n",
      "Epoch [3/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001588 --> 0.001448).  Saving model ...\n",
      "Epoch [4/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001448 --> 0.001378).  Saving model ...\n",
      "Epoch [5/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001378 --> 0.001336).  Saving model ...\n",
      "Epoch [6/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [7/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001336 --> 0.001333).  Saving model ...\n",
      "Epoch [8/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001333 --> 0.001309).  Saving model ...\n",
      "Epoch [9/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [10/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [11/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001309 --> 0.001304).  Saving model ...\n",
      "Epoch [12/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001304 --> 0.001184).  Saving model ...\n",
      "Epoch [13/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.001184 --> 0.000679).  Saving model ...\n",
      "Epoch [14/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [15/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000679 --> 0.000296).  Saving model ...\n",
      "Epoch [16/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000296 --> 0.000073).  Saving model ...\n",
      "Epoch [17/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000073 --> 0.000022).  Saving model ...\n",
      "Epoch [18/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000022 --> 0.000013).  Saving model ...\n",
      "Epoch [19/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000013 --> 0.000008).  Saving model ...\n",
      "Epoch [20/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000008 --> 0.000006).  Saving model ...\n",
      "Epoch [21/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000006 --> 0.000004).  Saving model ...\n",
      "Epoch [22/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000004 --> 0.000003).  Saving model ...\n",
      "Epoch [23/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000003 --> 0.000002).  Saving model ...\n",
      "Epoch [24/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000002 --> 0.000002).  Saving model ...\n",
      "Epoch [25/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000002 --> 0.000001).  Saving model ...\n",
      "Epoch [26/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000001 --> 0.000001).  Saving model ...\n",
      "Epoch [27/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000001 --> 0.000001).  Saving model ...\n",
      "Epoch [28/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000001 --> 0.000000).  Saving model ...\n",
      "Epoch [29/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [30/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [31/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [32/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [33/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [34/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [35/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [36/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [37/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [38/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [39/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [40/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [41/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [42/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch [43/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch [44/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch [45/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch [46/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch [47/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch [48/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch [49/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch [50/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch [51/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch [52/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch [53/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch [54/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [55/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [56/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [57/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [58/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [59/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [60/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [61/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [62/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [63/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [64/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [65/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [66/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [67/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [68/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch [69/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch [70/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch [71/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch [72/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch [73/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch [74/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch [75/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch [76/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch [77/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch [78/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch [79/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch [80/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch [81/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [82/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [83/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [84/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [85/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [86/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [87/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [88/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [89/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [90/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [91/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [92/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [93/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [94/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [95/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [96/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [97/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [98/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [99/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [100/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [101/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [102/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [103/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [104/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [105/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [106/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [107/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [108/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [109/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [110/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [111/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [112/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [113/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [114/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [115/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [116/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [117/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [118/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [119/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [120/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [121/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [122/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [123/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [124/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [125/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [126/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [127/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [128/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [129/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [130/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [131/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "Validation loss decreased (0.000000 --> 0.000000).  Saving model ...\n",
      "Epoch [132/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch [133/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch [134/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch [135/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch [136/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch [137/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch [138/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch [139/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 8 out of 30\n",
      "Epoch [140/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 9 out of 30\n",
      "Epoch [141/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 10 out of 30\n",
      "Epoch [142/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 11 out of 30\n",
      "Epoch [143/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 12 out of 30\n",
      "Epoch [144/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 13 out of 30\n",
      "Epoch [145/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 14 out of 30\n",
      "Epoch [146/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 15 out of 30\n",
      "Epoch [147/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 16 out of 30\n",
      "Epoch [148/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 17 out of 30\n",
      "Epoch [149/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 18 out of 30\n",
      "Epoch [150/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 19 out of 30\n",
      "Epoch [151/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 20 out of 30\n",
      "Epoch [152/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 21 out of 30\n",
      "Epoch [153/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 22 out of 30\n",
      "Epoch [154/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 23 out of 30\n",
      "Epoch [155/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 24 out of 30\n",
      "Epoch [156/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 25 out of 30\n",
      "Epoch [157/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 26 out of 30\n",
      "Epoch [158/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 27 out of 30\n",
      "Epoch [159/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 28 out of 30\n",
      "Epoch [160/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 29 out of 30\n",
      "Epoch [161/200] | Train Loss: 0.00 | Val Loss: 0.00\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping triggered\n",
      "Loading best model from 'best_model.pt' with validation loss: 0.00\n",
      "Confusion Matrix:\n",
      "[[4305    0]\n",
      " [   0 3195]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    1.00000   1.00000   1.00000      4305\n",
      "           1    1.00000   1.00000   1.00000      3195\n",
      "\n",
      "    accuracy                        1.00000      7500\n",
      "   macro avg    1.00000   1.00000   1.00000      7500\n",
      "weighted avg    1.00000   1.00000   1.00000      7500\n",
      "\n",
      "Total Errors: 0\n",
      "OK- Accuracy: 1.00, Precision: 1.00, Recall: 1.00, F1: 1.00, ROC AUC: 1.00, AUPR (PR-AUC): 1.00, Sensitivity: 1.00, Specificity: 1.00, Far: 0.0, False Positive Rate (FPR): 0.00, False Negative Rate (FNR): 0.00, Runtime: 0.20 sec , Memory Usage: 666.62 MB\n"
     ]
    }
   ],
   "source": [
    "backbone_config = {\n",
    "    'type': 'MLP',\n",
    "    'n_blocks': 2,\n",
    "    'd_block': 32,\n",
    "    'dropout': 0.1,\n",
    "}\n",
    "tabm = Model(\n",
    "    n_num_features=78,\n",
    "    cat_cardinalities=[],\n",
    "    n_classes=78,\n",
    "    backbone=backbone_config,\n",
    "    num_embeddings=None,\n",
    "    arch_type='tabm',\n",
    "    bins=None,\n",
    "    k=8\n",
    ")\n",
    "\n",
    "model = MODEL(tabm=tabm)\n",
    "\n",
    "start(train_loader2018, val_loader2018, test_loader2018, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
